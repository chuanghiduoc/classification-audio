
═══════════════════════════════════════════════════════════════════════
CNN MODEL FOR AUDIO CLASSIFICATION (PyTorch)
═══════════════════════════════════════════════════════════════════════

DATASET:
  - ESC-50: 2000 samples, 50 classes
  - Input: Mel Spectrogram (128x128)
  - Split: Train 7680 | Val 320 | Test 400
  - Augmentation: YES (6x for training only)
  - Device: cuda

MODEL ARCHITECTURE:
  - Type: Custom CNN (4 conv blocks + 3 FC layers)
  - Parameters: 1,279,506
  - Regularization: Dropout (0.2-0.4) + BatchNorm + L2 (1e-4)

TRAINING:
  - Epochs: 100 / 100
  - Best epoch: 87
  - Batch size: 32
  - Optimizer: Adam (lr=0.001, weight_decay=1e-4)
  - LR Scheduler: ReduceLROnPlateau
  - Early stopping: patience=20

RESULTS:
  - Train Accuracy: 89.43%
  - Val Accuracy: 83.44%
  - Test Accuracy: 0.8100 (81.00%)
  - Baseline (SVM): 76.25%
  - Improvement: +6.23%

OUTPUT FILES:
  ✓ best_cnn_improved_model.pth (trained weights)
  ✓ confusion_matrix_CNN_improved.png
  ✓ training_history_CNN_improved.png
  ✓ predictions_CNN.png
  ✓ cnn_model_info.txt

USAGE:
  from cnn_model import AudioCNN
  import torch
  
  model = AudioCNN(num_classes=50)
  model.load_state_dict(torch.load('best_cnn_improved_model.pth'))
  model.eval()

═══════════════════════════════════════════════════════════════════════
