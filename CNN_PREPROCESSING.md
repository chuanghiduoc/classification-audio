# ğŸ“Š TIá»€N Xá»¬ LÃ Dá»® LIá»†U & QUY TRÃŒNH CNN

**File:** `cnn_model.py`  
**Dataset (Táº­p dá»¯ liá»‡u):** ESC-50 (2000 audio files - file Ã¢m thanh, 50 classes - lá»›p)  
**Má»¥c tiÃªu:** PhÃ¢n loáº¡i Ã¢m thanh vá»›i CNN Ä‘áº¡t 98.62% accuracy (Ä‘á»™ chÃ­nh xÃ¡c)

---

## ğŸ”„ **QUY TRÃŒNH Tá»”NG QUAN**

```
Audio Files - File Ã¢m thanh (.wav)
    â†“
[1] Load Audio + Resampling (Táº£i Ã¢m thanh + Láº¥y máº«u láº¡i)
    â†“
[2] Padding/Trimming (Äá»‡m/Cáº¯t)
    â†“
[3] Data Augmentation - TÄƒng cÆ°á»ng dá»¯ liá»‡u (6x)
    â†“
[4] Mel Spectrogram - Phá»• táº§n Mel
    â†“
[5] Log Scaling - Biáº¿n Ä‘á»•i logarit
    â†“
[6] Normalization - Chuáº©n hÃ³a
    â†“
[7] Resize - Thay Ä‘á»•i kÃ­ch thÆ°á»›c
    â†“
[8] Train/Val/Test Split - Chia táº­p huáº¥n luyá»‡n/kiá»ƒm tra/Ä‘Ã¡nh giÃ¡
    â†“
[9] PyTorch Tensor - Chuyá»ƒn Ä‘á»•i sang tensor
    â†“
CNN Model (Training) - MÃ´ hÃ¬nh CNN (Huáº¥n luyá»‡n)
    â†“
Best Model - MÃ´ hÃ¬nh tá»‘t nháº¥t (98.62%)
```

---

## ğŸ“ **CHI TIáº¾T Tá»ªNG BÆ¯á»šC**

### **[1] LOAD AUDIO + RESAMPLING (Táº¢I Ã‚M THANH + Láº¤Y MáºªU Láº I)**

```python
y, sr = librosa.load(file_path, sr=22050, duration=5.0)
```

**Má»¥c Ä‘Ã­ch:**
- Äá»c file audio thÃ nh waveform - dáº¡ng sÃ³ng (1D signal - tÃ­n hiá»‡u 1 chiá»u)
- Chuáº©n hÃ³a sampling rate - táº§n sá»‘ láº¥y máº«u: 22050 Hz
- Láº¥y 5 giÃ¢y Ä‘áº§u tiÃªn (duration - Ä‘á»™ dÃ i)

**Input (Äáº§u vÃ o):** `dog_barking.wav` (audio file - file Ã¢m thanh)  
**Output (Äáº§u ra):** 
- `y`: (110250,) - waveform array (máº£ng dáº¡ng sÃ³ng)
- `sr`: 22050 Hz - sampling rate (táº§n sá»‘ láº¥y máº«u)

**LÃ½ do chá»n 22050 Hz:**
- Nyquist theorem - Äá»‹nh lÃ½ Nyquist: Capture (báº¯t) táº§n sá»‘ tá»›i 11025 Hz
- Äá»§ cho Ã¢m thanh tá»± nhiÃªn (human hearing - thÃ­nh giÃ¡c con ngÆ°á»i: 20-20000 Hz)
- Balance (cÃ¢n báº±ng) giá»¯a quality (cháº¥t lÆ°á»£ng) vÃ  computational cost (chi phÃ­ tÃ­nh toÃ¡n)

---

### **[2] PADDING/TRIMMING (Äá»†M/Cáº®T)**

```python
if len(y) < sr * 5:
    y = np.pad(y, (0, sr * 5 - len(y)), mode='constant')
```

**Má»¥c Ä‘Ã­ch:**
- Äáº£m báº£o má»i audio Ä‘á»u **Ä‘Ãºng 5 giÃ¢y** (110250 samples - máº«u)
- Audio ngáº¯n hÆ¡n â†’ Pad (Ä‘á»‡m) zeros (sá»‘ 0) vÃ o cuá»‘i
- Audio dÃ i hÆ¡n â†’ ÄÃ£ trim (cáº¯t) á»Ÿ bÆ°á»›c [1]

**VÃ­ dá»¥:**
```
Audio 3s = 66150 samples (máº«u)
Target (má»¥c tiÃªu) = 110250 samples
â†’ Pad (Ä‘á»‡m) thÃªm 44100 zeros (sá»‘ 0)
```

**Táº¡i sao cáº§n cá»‘ Ä‘á»‹nh length (Ä‘á»™ dÃ i)?**
- CNN yÃªu cáº§u input shape (kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o) cá»‘ Ä‘á»‹nh
- Batch processing (xá»­ lÃ½ theo lÃ´) cáº§n samples (máº«u) cÃ¹ng size (kÃ­ch thÆ°á»›c)

---

### **[3] DATA AUGMENTATION - TÄ‚NG CÆ¯á»œNG Dá»® LIá»†U (6x)**

**â­ Ká»¹ thuáº­t quan trá»ng Ä‘á»ƒ tÄƒng accuracy (Ä‘á»™ chÃ­nh xÃ¡c)!**

```python
# Original
mel_spec_original

# 1. Time Stretch (slow) - rate=0.9
y_slow = librosa.effects.time_stretch(y, rate=0.9)

# 2. Time Stretch (fast) - rate=1.1
y_fast = librosa.effects.time_stretch(y, rate=1.1)

# 3. Pitch Shift (+2 semitones)
y_pitch_up = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)

# 4. Pitch Shift (-2 semitones)
y_pitch_down = librosa.effects.pitch_shift(y, sr=sr, n_steps=-2)

# 5. Add Gaussian Noise
noise = np.random.randn(len(y)) * 0.005
y_noise = y + noise
```

**Káº¿t quáº£:**
```
1 audio file â†’ 6 variations
2000 files Ã— 6 = 12000 samples
```

**Lá»£i Ã­ch:**
- âœ… TÄƒng data (dá»¯ liá»‡u) 6x (2000 â†’ 12000)
- âœ… Model (mÃ´ hÃ¬nh) há»c Ä‘Æ°á»£c variations - biáº¿n thá»ƒ (tempo - nhá»‹p, pitch - cao Ä‘á»™, noise - nhiá»…u)
- âœ… Giáº£m overfitting - quÃ¡ khá»›p Ä‘Ã¡ng ká»ƒ
- âœ… Robust - á»•n Ä‘á»‹nh vá»›i variations trong real-world - tháº¿ giá»›i thá»±c

**Chi tiáº¿t tá»«ng augmentation (tÄƒng cÆ°á»ng):**

| Augmentation (TÄƒng cÆ°á»ng) | MÃ´ táº£ | Use Case (TrÆ°á»ng há»£p sá»­ dá»¥ng) |
|--------------|-------|----------|
| **Time Stretch (0.9) - KÃ©o giÃ£n thá»i gian** | LÃ m cháº­m 10% | Tiáº¿ng chÃ³ sá»§a cháº­m, ngÆ°á»i nÃ³i cháº­m |
| **Time Stretch (1.1) - KÃ©o giÃ£n thá»i gian** | LÃ m nhanh 10% | Tiáº¿ng chÃ³ sá»§a nhanh, ngÆ°á»i nÃ³i nhanh |
| **Pitch Shift (+2) - Dá»‹ch chuyá»ƒn cao Ä‘á»™** | TÄƒng cao Ä‘á»™ 2 ná»­a cung (semitones) | Tiáº¿ng chÃ³ nhá», giá»ng ná»¯ |
| **Pitch Shift (-2) - Dá»‹ch chuyá»ƒn cao Ä‘á»™** | Giáº£m cao Ä‘á»™ 2 ná»­a cung | Tiáº¿ng chÃ³ to, giá»ng nam |
| **Gaussian Noise - Nhiá»…u Gauss** | ThÃªm nhiá»…u ngáº«u nhiÃªn (Ïƒ=0.005) | MÃ´i trÆ°á»ng á»“n, nhiá»…u ná»n |

---

### **[4] MEL SPECTROGRAM - PHá»” Táº¦N MEL**

```python
mel_spec = librosa.feature.melspectrogram(
    y=y,
    sr=sr,
    n_mels=128,      # 128 frequency bins
    n_fft=2048,      # FFT window size
    hop_length=512,  # Overlap step
    fmax=8000        # Max frequency
)
```

**Má»¥c Ä‘Ã­ch:**
- Chuyá»ƒn waveform - dáº¡ng sÃ³ng (1D) â†’ Spectrogram - phá»• táº§n (2D time-frequency - thá»i gian-táº§n sá»‘)
- DÃ¹ng Mel scale - thang Mel (gáº§n vá»›i cÃ¡ch tai ngÆ°á»i nghe)

**Transformation (Chuyá»ƒn Ä‘á»•i):**
```
Input (Äáº§u vÃ o):  y = (110250,) waveform (dáº¡ng sÃ³ng)
Output (Äáº§u ra): mel_spec = (128, 216) time-frequency matrix (ma tráº­n thá»i gian-táº§n sá»‘)
```

**Parameters (Tham sá»‘):**

| Parameter (Tham sá»‘) | GiÃ¡ trá»‹ | Ã nghÄ©a |
|-----------|---------|---------|
| `n_mels` | 128 | 128 mel frequency bins - khoáº£ng táº§n sá»‘ mel (trá»¥c Y) |
| `n_fft` | 2048 | FFT window size - kÃ­ch thÆ°á»›c cá»­a sá»• FFT (Ä‘á»™ phÃ¢n giáº£i frequency - táº§n sá»‘) |
| `hop_length` | 512 | BÆ°á»›c nháº£y giá»¯a windows - cá»­a sá»• (overlap - chá»“ng láº¥n) |
| `fmax` | 8000 Hz | Frequency (táº§n sá»‘) tá»‘i Ä‘a (loáº¡i bá» high freq noise - nhiá»…u táº§n sá»‘ cao) |

**Mel Scale vs Linear (Thang Mel vs Tuyáº¿n tÃ­nh):**
```
Linear (Tuyáº¿n tÃ­nh): 1000 Hz, 2000 Hz, 3000 Hz, 4000 Hz
Mel:                 1000 Hz, 1500 Hz, 2000 Hz, 2500 Hz

â†’ Mel scale: DÃ y á»Ÿ táº§n sá»‘ tháº¥p, thÆ°a á»Ÿ táº§n sá»‘ cao
â†’ Giá»‘ng cÃ¡ch tai ngÆ°á»i nghe!
```

---

### **[5] LOG SCALING - BIáº¾N Äá»”I LOGARIT (dB - DECIBEL)**

```python
mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
```

**Má»¥c Ä‘Ã­ch:**
- Convert (chuyá»ƒn Ä‘á»•i) power - cÃ´ng suáº¥t â†’ decibel - Ä‘á»-xi-ben (dB)
- Giáº£m dynamic range - khoáº£ng Ä‘á»™ng
- Logarithmic scale - thang logarit (giá»‘ng cÃ¡ch tai ngÆ°á»i nghe)

**CÃ´ng thá»©c:**
```
dB = 10 Ã— log10(power / reference)
     (cÃ´ng suáº¥t / tham chiáº¿u)
```

**Hiá»‡u quáº£:**
```
Before (TrÆ°á»›c) - power (cÃ´ng suáº¥t):
  Range (khoáº£ng): 0.001 - 10 (10000x difference - chÃªnh lá»‡ch!)
  
After (Sau) - dB:
  Range (khoáº£ng): -30 dB to +10 dB (40 dB range)
  â†’ Dá»… xá»­ lÃ½ cho CNN!
```

---

### **[6] NORMALIZATION - CHUáº¨N HÃ“A [0, 1]**

```python
mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())
```

**Má»¥c Ä‘Ã­ch:**
- Chuáº©n hÃ³a (normalize) giÃ¡ trá»‹ vá» [0, 1]
- GiÃºp CNN training - huáº¥n luyá»‡n á»•n Ä‘á»‹nh
- Faster convergence - há»™i tá»¥ nhanh hÆ¡n, trÃ¡nh gradient issues - váº¥n Ä‘á» gradient

**CÃ´ng thá»©c:**
```
normalized (chuáº©n hÃ³a) = (x - min) / (max - min)
```

**VÃ­ dá»¥:**
```
Before (TrÆ°á»›c): [-80, -60, -40, -20, 0] dB
After (Sau):    [0, 0.25, 0.5, 0.75, 1.0]
```

**Lá»£i Ã­ch:**
- âœ… CNN weights - trá»ng sá»‘ há»c nhanh hÆ¡n vá»›i [0,1]
- âœ… TrÃ¡nh vanishing/exploding gradients - gradient tiÃªu biáº¿n/bÃ¹ng ná»•
- âœ… Stable training - huáº¥n luyá»‡n á»•n Ä‘á»‹nh

---

### **[7] RESIZE - THAY Äá»”I KÃCH THÆ¯á»šC TO 128Ã—128**

```python
mel_spec_resized = cv2.resize(mel_spec_norm, (128, 128))
```

**Má»¥c Ä‘Ã­ch:**
- Resize (thay Ä‘á»•i kÃ­ch thÆ°á»›c) tá»« (128, 216) â†’ (128, 128) square - hÃ¬nh vuÃ´ng
- Cá»‘ Ä‘á»‹nh input shape - kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o cho CNN

**Transformation (Chuyá»ƒn Ä‘á»•i):**
```
Before (TrÆ°á»›c): (128 freq - táº§n sá»‘, 216 time - thá»i gian) - rectangular (hÃ¬nh chá»¯ nháº­t)
After (Sau):    (128, 128) - square image (áº£nh vuÃ´ng)
```

**LÃ½ do resize:**
- CNN design - thiáº¿t káº¿ dá»… hÆ¡n vá»›i square input - Ä‘áº§u vÃ o vuÃ´ng
- Giáº£m sá»‘ parameters - tham sá»‘ (216 â†’ 128 á»Ÿ time axis - trá»¥c thá»i gian)
- Standard - chuáº©n cho computer vision models - mÃ´ hÃ¬nh thá»‹ giÃ¡c mÃ¡y tÃ­nh

---

### **[8] TRAIN/VAL/TEST SPLIT - CHIA Táº¬P HUáº¤N LUYá»†N/KIá»‚M TRA/ÄÃNH GIÃ**

```python
# Step 1: Train/Test split (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Step 2: Train â†’ Train/Val split (80/20)
train_size = int(0.8 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_subset, val_subset = random_split(train_dataset, [train_size, val_size])
```

**Káº¿t quáº£:**
```
Total (Tá»•ng): 12000 samples - máº«u (sau augmentation - tÄƒng cÆ°á»ng)

â”œâ”€ Train (Huáº¥n luyá»‡n): 7680 samples (64%)
â”‚  â””â”€ DÃ¹ng Ä‘á»ƒ train model - huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚
â”œâ”€ Val (Validation - Kiá»ƒm tra):   1920 samples (16%)
â”‚  â””â”€ Monitor overfitting - theo dÃµi quÃ¡ khá»›p, early stopping - dá»«ng sá»›m, 
â”‚     LR scheduling - láº­p lá»‹ch learning rate
â”‚
â””â”€ Test (ÄÃ¡nh giÃ¡):  2400 samples (20%)
   â””â”€ Final evaluation - Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng (khÃ´ng Ä‘á»™ng Ä‘áº¿n trong training - huáº¥n luyá»‡n)
```

**Stratified sampling - Láº¥y máº«u phÃ¢n táº§ng:**
- Äáº£m báº£o má»—i class - lá»›p cÃ³ tá»· lá»‡ Ä‘á»u trong train/val/test
- TrÃ¡nh class imbalance - máº¥t cÃ¢n báº±ng lá»›p

---

### **[9] PYTORCH TENSOR - CHUYá»‚N Äá»”I SANG TENSOR**

```python
# Reshape: (samples, height, width) â†’ (samples, channels, height, width)
X = spectrograms.reshape(-1, 1, IMG_SIZE, IMG_SIZE)

# Convert to PyTorch Tensor
self.spectrograms = torch.FloatTensor(spectrograms)
self.labels = torch.LongTensor(labels)
```

**Transformation (Chuyá»ƒn Ä‘á»•i):**
```
NumPy:   (12000, 128, 128)
PyTorch: (12000, 1, 128, 128)
         (batch - lÃ´, channels - kÃªnh, height - cao, width - rá»™ng)
```

**Channel dimension - Chiá»u kÃªnh:**
- Mel spectrogram = Grayscale image - áº£nh xÃ¡m â†’ 1 channel - kÃªnh
- RGB image - áº£nh RGB â†’ 3 channels - kÃªnh
- CNN expects - yÃªu cáº§u (N, C, H, W) format - Ä‘á»‹nh dáº¡ng

---

## ğŸ—ï¸ **CNN ARCHITECTURE - KIáº¾N TRÃšC CNN**

### **Model Overview - Tá»•ng quan mÃ´ hÃ¬nh:**

```python
AudioCNN(
  # Block 1: Low-level features - Äáº·c trÆ°ng cáº¥p tháº¥p (edges - cáº¡nh, textures - káº¿t cáº¥u)
  Conv2d(1 â†’ 32) â†’ Conv2d(32 â†’ 32) â†’ MaxPool â†’ BatchNorm â†’ Dropout(0.25)
  
  # Block 2: Mid-level features - Äáº·c trÆ°ng cáº¥p trung (patterns - máº«u)
  Conv2d(32 â†’ 64) â†’ Conv2d(64 â†’ 64) â†’ MaxPool â†’ BatchNorm â†’ Dropout(0.25)
  
  # Block 3: High-level features - Äáº·c trÆ°ng cáº¥p cao (sound signatures - dáº¥u hiá»‡u Ã¢m thanh)
  Conv2d(64 â†’ 128) â†’ Conv2d(128 â†’ 128) â†’ MaxPool â†’ BatchNorm â†’ Dropout(0.25)
  
  # Block 4: Abstract features - Äáº·c trÆ°ng trá»«u tÆ°á»£ng (class-specific - Ä‘áº·c thÃ¹ tá»«ng lá»›p)
  Conv2d(128 â†’ 256) â†’ Conv2d(256 â†’ 256) â†’ AdaptiveAvgPool
  
  # Fully Connected Layers - Lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§
  FC(256 â†’ 512) â†’ BatchNorm â†’ Dropout(0.5)
  FC(512 â†’ 256) â†’ BatchNorm â†’ Dropout(0.3)
  FC(256 â†’ 50) â†’ Softmax
)
```

**Trainable parameters - Tham sá»‘ huáº¥n luyá»‡n:** 1,449,426

---

## ğŸ“ **TRAINING STRATEGY - CHIáº¾N LÆ¯á»¢C HUáº¤N LUYá»†N**

### **Optimizer - Bá»™ tá»‘i Æ°u & Loss - HÃ m máº¥t mÃ¡t:**
```python
optimizer = Adam(lr=0.001)  # lr = learning rate - tá»‘c Ä‘á»™ há»c
criterion = CrossEntropyLoss()  # HÃ m máº¥t mÃ¡t phÃ¢n loáº¡i Ä‘a lá»›p
```

### **Learning Rate Scheduling - Láº­p lá»‹ch tá»‘c Ä‘á»™ há»c:**
```python
scheduler = ReduceLROnPlateau(  # Giáº£m LR khi plateau - Ä‘áº¡t bÃ¬nh nguyÃªn
    mode='min',  # Cháº¿ Ä‘á»™: tá»‘i thiá»ƒu hÃ³a
    factor=0.5,     # LR_new (má»›i) = LR_old (cÅ©) Ã— 0.5
    patience=5,     # Äá»£i 5 epochs - ká»· nguyÃªn
    verbose=True  # In thÃ´ng bÃ¡o
)
```

**CÆ¡ cháº¿:**
- Monitor (theo dÃµi) `val_loss` - máº¥t mÃ¡t kiá»ƒm tra má»—i epoch
- Náº¿u khÃ´ng giáº£m trong 5 epochs â†’ Giáº£m LR
- LR: 0.001 â†’ 0.0005 â†’ 0.00025 â†’ ...

### **Regularization - Äiá»u chuáº©n:**
1. **Dropout - Bá» qua ngáº«u nhiÃªn:** 0.25 (Conv blocks - khá»‘i tÃ­ch cháº­p), 0.5 (FC1), 0.3 (FC2)
2. **BatchNormalization - Chuáº©n hÃ³a theo lÃ´:** Sau má»—i Conv vÃ  FC layer - lá»›p
3. **Data Augmentation - TÄƒng cÆ°á»ng dá»¯ liá»‡u:** 6x (quan trá»ng nháº¥t!)
4. **Early Stopping - Dá»«ng sá»›m:** Patience - Ä‘á»™ kiÃªn nháº«n = 15 epochs

### **Training Config:**
```python
EPOCHS = 100
BATCH_SIZE = 32
DEVICE = 'cuda' (RTX 3050)
```

---

## ğŸ“Š **Káº¾T QUáº¢**

### **Final Performance - Hiá»‡u suáº¥t cuá»‘i cÃ¹ng:**
```
Test Accuracy - Äá»™ chÃ­nh xÃ¡c kiá»ƒm tra:    98.62%
Val Accuracy - Äá»™ chÃ­nh xÃ¡c validation:   98.80%
Train Accuracy - Äá»™ chÃ­nh xÃ¡c huáº¥n luyá»‡n: 98.97%

Train-Val Gap - Khoáº£ng cÃ¡ch: 0.17% (ráº¥t tháº¥p â†’ khÃ´ng overfit - quÃ¡ khá»›p)
Val-Test Gap - Khoáº£ng cÃ¡ch:  0.18% (generalization - kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t)
```

### **So sÃ¡nh vá»›i Traditional ML - Há»c mÃ¡y truyá»n thá»‘ng:**

| Model - MÃ´ hÃ¬nh | Accuracy - Äá»™ chÃ­nh xÃ¡c | Training Time - Thá»i gian huáº¥n luyá»‡n | Input - Äáº§u vÃ o |
|-------|----------|---------------|-------|
| SVM (Traditional - Truyá»n thá»‘ng) | 76.25% | ~2 phÃºt | 421 handcrafted features - Ä‘áº·c trÆ°ng thá»§ cÃ´ng |
| **CNN (Deep Learning - Há»c sÃ¢u)** | **98.62%** | **~27 phÃºt** | **Raw spectrogram - Phá»• táº§n thÃ´** |
| **Improvement - Cáº£i thiá»‡n** | **+29.34%** | - | End-to-end learning - Há»c Ä‘áº§u-cuá»‘i |

---

## ğŸ¯ **Táº I SAO CNN Máº NH HÆ N SVM?**

### **1. Input Representation - Biá»ƒu diá»…n Ä‘áº§u vÃ o:**

**SVM:**
```
Audio â†’ Extract MFCC, Mel, Spectral... â†’ 421 features
      â†’ SelectKBest â†’ 200 features
      â†’ SVM â†’ 76.25%

Váº¥n Ä‘á»:
- Handcrafted features cÃ³ thá»ƒ bá» sÃ³t thÃ´ng tin
- Fixed features cho má»i loáº¡i Ã¢m thanh
```

**CNN:**
```
Audio â†’ Mel Spectrogram (128Ã—128 = 16,384 pixels)
      â†’ CNN tá»± há»c features
      â†’ 98.62%

Æ¯u Ä‘iá»ƒm:
- Raw spectrogram giá»¯ toÃ n bá»™ thÃ´ng tin
- CNN tá»± Ä‘á»™ng há»c features tá»‘i Æ°u
- Hierarchical learning: low â†’ high level
```

### **2. Feature Learning - Há»c Ä‘áº·c trÆ°ng:**

**SVM:** Features - Äáº·c trÆ°ng do con ngÆ°á»i thiáº¿t káº¿  
**CNN:** Features tá»± Ä‘á»™ng há»c tá»« data - dá»¯ liá»‡u

```
CNN Layer 1: Edges - cáº¡nh, corners - gÃ³c, textures - káº¿t cáº¥u
CNN Layer 2: Frequency bands - dáº£i táº§n, patterns - máº«u
CNN Layer 3: Sound signatures - dáº¥u hiá»‡u Ã¢m thanh (chÃ³ sá»§a, mÃ¨o kÃªu...)
CNN Layer 4: Class-specific representations - biá»ƒu diá»…n Ä‘áº·c thÃ¹ tá»«ng lá»›p
```

### **3. Data Augmentation - TÄƒng cÆ°á»ng dá»¯ liá»‡u:**

**SVM:** 
- Augmentation - TÄƒng cÆ°á»ng trÃªn features - Ä‘áº·c trÆ°ng (khÃ³)
- Sá»­ dá»¥ng ADASYN (synthetic samples - máº«u tá»•ng há»£p)

**CNN:** 
- Augmentation trÃªn audio (dá»… vÃ  hiá»‡u quáº£)
- 6 loáº¡i augmentation â†’ 6x data
- Model robust - á»•n Ä‘á»‹nh vá»›i variations - biáº¿n thá»ƒ

---

## ğŸ”‘ **NHá»®NG ÄIá»‚M QUAN TRá»ŒNG**

### **âœ… Preprocessing - Tiá»n xá»­ lÃ½ tá»‘t nháº¥t:**

1. **Mel Spectrogram - Phá»• táº§n Mel** thay vÃ¬ raw waveform - dáº¡ng sÃ³ng thÃ´
   - Giáº£m dimensionality - sá»‘ chiá»u: 110250 â†’ 128Ã—128
   - Perceptually relevant - liÃªn quan tri giÃ¡c (Mel scale - thang Mel)
   - Capture - báº¯t time-frequency patterns - máº«u thá»i gian-táº§n sá»‘

2. **Log scaling - Biáº¿n Ä‘á»•i logarit (dB)**
   - Giáº£m dynamic range - khoáº£ng Ä‘á»™ng
   - Giá»‘ng cÃ¡ch tai ngÆ°á»i nghe

3. **Normalization - Chuáº©n hÃ³a [0,1]**
   - Stable training - huáº¥n luyá»‡n á»•n Ä‘á»‹nh
   - Faster convergence - há»™i tá»¥ nhanh hÆ¡n

4. **Data Augmentation - TÄƒng cÆ°á»ng dá»¯ liá»‡u 6x**
   - TÄƒng data 2000 â†’ 12000
   - Giáº£m overfitting - quÃ¡ khá»›p
   - Robust model - mÃ´ hÃ¬nh á»•n Ä‘á»‹nh

### **âœ… Training strategy - Chiáº¿n lÆ°á»£c huáº¥n luyá»‡n tá»‘t nháº¥t:**

1. **Learning Rate Scheduling - Láº­p lá»‹ch tá»‘c Ä‘á»™ há»c**
   - Adaptive LR - LR thÃ­ch á»©ng: 0.001 â†’ 0.0005 â†’ ...
   - Converge - há»™i tá»¥ chÃ­nh xÃ¡c hÆ¡n

2. **Regularization - Äiá»u chuáº©n nhiá»u lá»›p**
   - Dropout + BatchNorm + Augmentation
   - Train 98.97%, Val 98.80% (gap - khoáº£ng cÃ¡ch chá»‰ 0.17%)

3. **Early Stopping - Dá»«ng sá»›m**
   - TrÃ¡nh waste time - lÃ£ng phÃ­ thá»i gian
   - Restore best weights - khÃ´i phá»¥c trá»ng sá»‘ tá»‘t nháº¥t

---

## ğŸ“ˆ **WORKFLOW THá»°C Táº¾**

### **Khi train model:**

```bash
$ python cnn_model.py

# Output:
1. Load 2000 audio files
2. Extract Mel Spectrograms
3. Apply augmentation (6x) â†’ 12000 samples
4. Split: Train 7680 | Val 1920 | Test 2400
5. Build CNN (1.4M parameters)
6. Train 100 epochs vá»›i:
   - Adam optimizer (lr=0.001)
   - LR scheduling
   - Early stopping
7. Best model: Epoch 99 (Val Acc: 98.80%)
8. Test evaluation: 98.62%
9. Save:
   - best_cnn_model.pth
   - confusion_matrix_CNN.png
   - training_history_CNN.png
   - predictions_CNN.png
   - cnn_model_info.txt
```

### **Training time:**
- ~17s/epoch Ã— 100 epochs = ~27 phÃºt (vá»›i RTX 3050)
- CPU: ~2-3 giá»

---

## ğŸš€ **TIPS Tá»I Æ¯U HÃ“A - Máº¸O Tá»I Æ¯U**

### **Náº¿u accuracy - Ä‘á»™ chÃ­nh xÃ¡c tháº¥p (<90%):**

1. **TÄƒng augmentation - tÄƒng cÆ°á»ng:**
   - ThÃªm time shift - dá»‹ch thá»i gian, volume change - thay Ä‘á»•i Ã¢m lÆ°á»£ng
   - Frequency masking - che táº§n sá»‘ (SpecAugment)

2. **Train - huáº¥n luyá»‡n lÃ¢u hÆ¡n:**
   - EPOCHS = 150
   - Early stopping patience - Ä‘á»™ kiÃªn nháº«n = 20

3. **TÄƒng model capacity - dung lÆ°á»£ng mÃ´ hÃ¬nh:**
   - ThÃªm 1 Conv block - khá»‘i tÃ­ch cháº­p
   - TÄƒng filters - bá»™ lá»c: 32â†’64, 64â†’128...

### **Náº¿u overfitting - quÃ¡ khá»›p:**

1. **TÄƒng regularization - Ä‘iá»u chuáº©n:**
   - Dropout 0.5 â†’ 0.6-0.7
   - L2 weight decay - phÃ¢n rÃ£ trá»ng sá»‘

2. **TÄƒng augmentation - tÄƒng cÆ°á»ng:**
   - 6x â†’ 9x hoáº·c 12x

3. **Giáº£m model size - kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh:**
   - Giáº£m filters - bá»™ lá»c: 32â†’16, 64â†’32...

### **Náº¿u training - huáº¥n luyá»‡n cháº­m:**

1. **Giáº£m batch size - kÃ­ch thÆ°á»›c lÃ´:** 32 â†’ 16
2. **Giáº£m IMG_SIZE - kÃ­ch thÆ°á»›c áº£nh:** 128 â†’ 64
3. **DÃ¹ng GPU máº¡nh hÆ¡n**

---

## ğŸ“š **TÃ€I LIá»†U THAM KHáº¢O**

### **Code structure:**
- `cnn_model.py`: Main file
- `best_cnn_model.pth`: Trained weights
- `confusion_matrix_CNN.png`: Confusion matrix
- `training_history_CNN.png`: Training curves

### **Libraries:**
- `librosa`: Audio processing
- `PyTorch`: Deep learning framework
- `cv2`: Image resizing
- `sklearn`: Train/test split

### **Dataset - Táº­p dá»¯ liá»‡u:**
- **ESC-50:** Environmental Sound Classification - PhÃ¢n loáº¡i Ã¢m thanh mÃ´i trÆ°á»ng
- 2000 audio files - file Ã¢m thanh, 50 classes - lá»›p
- 5 seconds - giÃ¢y each - má»—i file, 44.1 kHz

---

**TÃ¡c giáº£:** AI Assistant  
**NgÃ y:** 2025-10-15  
**Version:** 1.0 (PyTorch CNN)

