# ğŸ“š TÃ€I LIá»†U GIáº¢I THÃCH - PHÃ‚N LOáº I Ã‚M THANH ESC50

## ğŸ“‹ **Má»¤C Lá»¤C**
1. [Káº¿t quáº£ thá»±c nghiá»‡m](#káº¿t-quáº£-thá»±c-nghiá»‡m)
2. [Pipeline tiá»n xá»­ lÃ½ dá»¯ liá»‡u](#pipeline-tiá»n-xá»­-lÃ½-dá»¯-liá»‡u) â­ Má»šI
3. [Giáº£i thÃ­ch tá»«ng model](#giáº£i-thÃ­ch-tá»«ng-model)
4. [So sÃ¡nh vÃ  káº¿t luáº­n](#so-sÃ¡nh-vÃ -káº¿t-luáº­n)

---

## ğŸ¯ **Káº¾T QUáº¢ THá»°C NGHIá»†M**

### **ğŸ“Š Báº¢NG Xáº¾P Háº NG**
```
1. SVM               76.25% â­ THáº®NG
2. Ensemble Voting   75.25%
3. Random Forest     72.75%
4. XGBoost          70.50%
5. Neural Network    69.50%
6. KNN              58.25%
```

---

## ğŸ” **Táº I SAO SVM THáº®NG Vá»šI Dá»® LIá»†U Ã‚M THANH NÃ€Y?**

### **1ï¸âƒ£ Äáº¶C ÄIá»‚M Dá»® LIá»†U Ã‚M THANH (421 â†’ 200 features)**
- âœ… **High-dimensional** (200 chiá»u sau selection)
- âœ… **Tuyáº¿n tÃ­nh khÃ³ phÃ¢n tÃ¡ch** trong khÃ´ng gian gá»‘c
- âœ… **Nhiá»u classes** (50 loáº¡i Ã¢m thanh)
- âœ… **Dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a tá»‘t** (RobustScaler)
- âœ… **Features cÃ³ Ã½ nghÄ©a** (MFCC, Mel, Spectral...)

### **2ï¸âƒ£ Táº I SAO SVM Máº NH á» ÄÃ‚Y?**

**âœ… Kernel RBF (Radial Basis Function)**
- Biáº¿n Ä‘á»•i dá»¯ liá»‡u lÃªn **khÃ´ng gian vÃ´ háº¡n chiá»u**
- TÃ¬m Ä‘Æ°á»£c **ranh giá»›i phi tuyáº¿n phá»©c táº¡p**
- Ã‚m thanh "dog" vÃ  "cat" cÃ³ thá»ƒ ráº¥t giá»‘ng á»Ÿ khÃ´ng gian gá»‘c, nhÆ°ng RBF tÃ¡ch Ä‘Æ°á»£c

**âœ… C=100 (Regularization)**
- `C` cao = cho phÃ©p mÃ´ hÃ¬nh **phá»©c táº¡p hÆ¡n**
- Vá»›i 200 features vÃ  1600 samples â†’ cáº§n C cao Ä‘á»ƒ fit tá»‘t
- KhÃ´ng quÃ¡ overfitting vÃ¬ Ä‘Ã£ cÃ³ RobustScaler + Feature Selection

**âœ… Hoáº¡t Ä‘á»™ng tá»‘t vá»›i dá»¯ liá»‡u Ã­t**
- Dataset chá»‰ cÃ³ 1600 train samples
- SVM tá»‘i Æ°u hÃ³a **margin**, khÃ´ng cáº§n nhiá»u data nhÆ° Deep Learning

---

## ğŸ”§ **PIPELINE TIá»€N Xá»¬ LÃ Dá»® LIá»†U**

### **ğŸ“Š Tá»”NG QUAN PIPELINE**

```
Audio Files (2000 Ã— 5s WAV)
    â†“
[1] Feature Extraction â†’ (2000, 421) raw features
    â†“
[2] Train/Test Split â†’ Train: 1600 | Test: 400
    â†“
[3] RobustScaler â†’ Chuáº©n hÃ³a vá» mean=median, scale=IQR
    â†“
[4] Giá»¯ toÃ n bá»™ dá»¯ liá»‡u â†’ KhÃ´ng loáº¡i outliers
    â†“
[5] SelectKBest â†’ Chá»n 200 features tá»‘t nháº¥t (F-test)
    â†“
[6] ADASYN â†’ Táº¡o synthetic samples (1600 â†’ 1600 balanced)
    â†“
Model Training (SVM, RF, XGBoost, NN, Ensemble)
```

---

### **ğŸµ BÆ¯á»šC 1: FEATURE EXTRACTION (421 FEATURES)**

#### **Má»¥c Ä‘Ã­ch:**
Biáº¿n Ä‘á»•i audio waveform â†’ vector sá»‘ há»c mÃ  ML cÃ³ thá»ƒ há»c

#### **CÃ¡c features trÃ­ch xuáº¥t:**

**1. MFCC (Mel-Frequency Cepstral Coefficients) - 240 features**
```python
mfccs = librosa.feature.mfcc(y, sr, n_mfcc=40)
â†’ Mean (40), Std (40), Max (40), Min (40)
â†’ Delta (40), DeltaÂ² (40)
```
**Ã nghÄ©a:**
- MFCC mÃ´ phá»ng cÃ¡ch tai ngÆ°á»i nghe
- Táº­p trung vÃ o táº§n sá»‘ tháº¥p (quan trá»ng cho speech/sound)
- **Mean/Std**: Äáº·c trÆ°ng trung bÃ¬nh, Ä‘á»™ biáº¿n thiÃªn
- **Max/Min**: GiÃ¡ trá»‹ cá»±c trá»‹ (VD: tiáº¿ng ná»• cÃ³ peak cao)
- **Delta**: Tá»‘c Ä‘á»™ thay Ä‘á»•i MFCC theo thá»i gian

**Táº¡i sao quan trá»ng?**
- Tiáº¿ng chÃ³ sá»§a: MFCC khÃ¡c tiáº¿ng mÃ¨o kÃªu
- Tiáº¿ng cÃ²i xe: MFCC cÃ³ pattern Ä‘áº·c trÆ°ng

**2. Mel Spectrogram - 80 features**
```python
mel = librosa.feature.melspectrogram(y, sr, n_mels=128)
â†’ Mean (20), Std (20), Max (20), Median (20)
```
**Ã nghÄ©a:**
- PhÃ¢n tÃ­ch nÄƒng lÆ°á»£ng theo táº§n sá»‘ (Mel scale)
- **Mean**: NÄƒng lÆ°á»£ng trung bÃ¬nh má»—i band
- **Max**: Peak nÄƒng lÆ°á»£ng (tiáº¿ng ná»•)
- **Median**: Robust vá»›i outliers

**3. Tempogram - 20 features**
```python
tempogram = librosa.feature.tempogram(y, sr)
â†’ Mean (10), Std (10)
```
**Ã nghÄ©a:**
- PhÃ¡t hiá»‡n nhá»‹p Ä‘iá»‡u, tempo
- Tiáº¿ng chÃ³ sá»§a: cÃ³ rhythm
- Tiáº¿ng giÃ³: khÃ´ng cÃ³ rhythm rÃµ

**4. Chroma - 36 features**
```python
chroma = librosa.feature.chroma_stft(y, sr)
â†’ Mean (12), Std (12), Max (12)
```
**Ã nghÄ©a:**
- 12 pitch classes (C, C#, D, ...)
- Quan trá»ng cho Ã¢m nháº¡c, tiáº¿ng chuÃ´ng
- Ãt quan trá»ng cho tiáº¿ng Ä‘á»™ng váº­t, tiáº¿ng á»“n

**5. Spectral Features - 17 features**
```python
# Zero Crossing Rate
zcr = librosa.feature.zero_crossing_rate(y)
â†’ Mean, Std, Max (3)

# Spectral Centroid (tÃ¢m phá»• táº§n)
centroid = librosa.feature.spectral_centroid(y, sr)
â†’ Mean, Std, Max (3)

# Spectral Bandwidth (Ä‘á»™ rá»™ng phá»•)
bandwidth = librosa.feature.spectral_bandwidth(y, sr)
â†’ Mean, Std, Max (3)

# Spectral Rolloff (85% nÄƒng lÆ°á»£ng)
rolloff = librosa.feature.spectral_rolloff(y, sr)
â†’ Mean, Std, Max (3)

# Spectral Contrast
contrast = librosa.feature.spectral_contrast(y, sr)
â†’ Mean (7), Std (7)

# Spectral Flatness (Ä‘á»™ "pháº³ng" cá»§a phá»•)
flatness = librosa.feature.spectral_flatness(y)
â†’ Mean, Std (2)
```

**Ã nghÄ©a tá»«ng features:**

| Feature | Ã nghÄ©a | VÃ­ dá»¥ |
|---------|---------|-------|
| **Zero Crossing Rate** | Táº§n sá»‘ Ä‘á»•i dáº¥u | Tiáº¿ng giÃ³ cao, tiáº¿ng bass tháº¥p |
| **Spectral Centroid** | Táº§n sá»‘ "trung tÃ¢m" | Tiáº¿ng ná»¯ ~250Hz, tiáº¿ng nam ~125Hz |
| **Spectral Bandwidth** | Äá»™ rá»™ng phá»• | Tiáº¿ng á»“n: rá»™ng, Tiáº¿ng sin: háº¹p |
| **Spectral Rolloff** | NgÆ°á»¡ng 85% nÄƒng lÆ°á»£ng | Tiáº¿ng bass tháº¥p, tiáº¿ng cymbal cao |
| **Spectral Contrast** | ChÃªnh lá»‡ch peak-valley | Tiáº¿ng nÃ³i: cao, Tiáº¿ng á»“n tráº¯ng: tháº¥p |
| **Spectral Flatness** | Äá»™ "á»“n" | 0=tonal (nháº¡c), 1=noise (giÃ³) |

**6. RMS Energy - 3 features**
```python
rms = librosa.feature.rms(y)
â†’ Mean, Std, Max (3)
```
**Ã nghÄ©a:**
- NÄƒng lÆ°á»£ng/Ã¢m lÆ°á»£ng
- Tiáº¿ng ná»•: RMS cao
- Tiáº¿ng thÃ¬ tháº§m: RMS tháº¥p

**7. Tonnetz (Tonal Centroid) - 12 features**
```python
tonnetz = librosa.feature.tonnetz(y, sr)
â†’ Mean (6), Std (6)
```
**Ã nghÄ©a:**
- Biá»ƒu diá»…n hÃ²a Ã¢m
- Quan trá»ng cho nháº¡c cá»¥
- Ãt quan trá»ng cho tiáº¿ng Ä‘á»™ng váº­t

**8. Poly Features - 2 features**
```python
poly = librosa.feature.poly_features(y, sr, order=1)
â†’ Mean (2)
```
**Ã nghÄ©a:**
- Polynomial coefficients cá»§a STFT
- MÃ´ hÃ¬nh hÃ³a hÃ¬nh dáº¡ng phá»• táº§n

---

### **âœ‚ï¸ BÆ¯á»šC 2: TRAIN/TEST SPLIT (80/20)**

```python
X_train: 1600 samples (80%)
X_test:   400 samples (20%)

stratify=labels  # Äáº£m báº£o má»—i class cÃ³ tá»· lá»‡ Ä‘á»u trong train/test
random_state=42  # Reproducible
```

**Táº¡i sao 80/20?**
- âœ… Standard practice
- âœ… Äá»§ data Ä‘á»ƒ train (1600)
- âœ… Äá»§ data Ä‘á»ƒ test (400 = 8 samples/class)
- âœ… Stratified â†’ má»—i class cÃ³ 32 train, 8 test

**Táº¡i sao khÃ´ng 90/10?**
- âš ï¸ Test set quÃ¡ nhá» (200 samples = 4/class)
- âš ï¸ Káº¿t quáº£ khÃ´ng stable

**Táº¡i sao khÃ´ng 70/30?**
- âš ï¸ Máº¥t data train (1400 vs 1600)
- âš ï¸ Vá»›i 50 classes, cáº§n nhiá»u data train

---

### **ğŸ“ BÆ¯á»šC 3: ROBUSTSCALER - CHUáº¨N HÃ“A**

#### **CÃ´ng thá»©c:**
```python
X_scaled = (X - median) / IQR

Trong Ä‘Ã³:
- median: Trung vá»‹ (50th percentile)
- IQR: Interquartile Range = Q3 - Q1 (75th - 25th percentile)
```

#### **Táº¡i sao dÃ¹ng RobustScaler?**

**So sÃ¡nh vá»›i StandardScaler:**
```
StandardScaler: X_scaled = (X - mean) / std

Váº¥n Ä‘á»:
- Mean vÃ  std bá»‹ áº£nh hÆ°á»Ÿng Máº NH bá»Ÿi outliers
- Ã‚m thanh cÃ³ nhiá»u outliers tá»± nhiÃªn (tiáº¿ng ná»•, peak)

VÃ­ dá»¥:
Features: [1, 2, 3, 4, 100]  â† 100 lÃ  outlier

StandardScaler:
  mean = 22, std = 43.3
  Scaled: [-0.49, -0.46, -0.44, -0.41, 1.80]
  â†’ Háº§u háº¿t features bá»‹ nÃ©n vá» [-0.5, 0], outlier = 1.8

RobustScaler:
  median = 3, IQR = 3
  Scaled: [-0.67, -0.33, 0, 0.33, 32.3]
  â†’ CÃ¡c features bÃ¬nh thÆ°á»ng váº«n spread tá»‘t
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… **Robust vá»›i outliers** - KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi giÃ¡ trá»‹ cá»±c trá»‹
- âœ… **Giá»¯ Ä‘Æ°á»£c phÃ¢n phá»‘i** - KhÃ´ng lÃ m máº¥t thÃ´ng tin vá» outliers
- âœ… **PhÃ¹ há»£p vá»›i audio** - Ã‚m thanh cÃ³ peak tá»± nhiÃªn (tiáº¿ng ná»•, tiáº¿ng Ä‘áº­p)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ KhÃ´ng scale vá» [0, 1] cá»‘ Ä‘á»‹nh (nhÆ°ng khÃ´ng cáº§n thiáº¿t)

**So sÃ¡nh cÃ¡c Scaler:**

| Scaler | CÃ´ng thá»©c | Khi nÃ o dÃ¹ng | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|--------|-----------|--------------|---------|------------|
| **RobustScaler** âœ… | (X-median)/IQR | **Nhiá»u outliers** | Robust, giá»¯ phÃ¢n phá»‘i | KhÃ´ng bound [0,1] |
| StandardScaler | (X-mean)/std | PhÃ¢n phá»‘i chuáº©n | Phá»• biáº¿n, nhanh | Nháº¡y outliers |
| MinMaxScaler | (X-min)/(max-min) | Cáº§n scale [0,1] | Dá»… hiá»ƒu, bound | Ráº¥t nháº¡y outliers |
| Normalizer | X/||X|| | Sparse data, text | Normalize theo row | KhÃ´ng phÃ¹ há»£p tabular |

**Káº¿t quáº£:**
```
Input:  (1600, 421) - Raw features
Output: (1600, 421) - Scaled features
        Mean â‰ˆ 0, Scale â‰ˆ 1 (nhÆ°ng dÃ¹ng median/IQR)
```

---

### **ğŸš« BÆ¯á»šC 4: KHÃ”NG LOáº I OUTLIERS**

#### **Quyáº¿t Ä‘á»‹nh:**
```python
X_train_cleaned = X_train_scaled  # Giá»¯ nguyÃªn
y_train_cleaned = y_train_advanced
```

#### **Táº¡i sao KHÃ”NG loáº¡i outliers?**

**PhiÃªn báº£n cÅ© (Ä‘Ã£ loáº¡i bá»):**
```python
z_scores = np.abs(stats.zscore(X_train))
outliers = (z_scores > 5).any(axis=1)
X_clean = X_train[~outliers]  # Máº¥t 181 samples!
```

**Váº¥n Ä‘á» cá»§a viá»‡c loáº¡i outliers:**
1. **Máº¥t data** 
   - Máº¥t 181/1600 = 11.3% data
   - Vá»›i 50 classes, má»—i class chá»‰ cÃ³ ~32 samples
   - Máº¥t 11% â†’ cÃ²n ~28 samples/class â†’ quÃ¡ Ã­t!

2. **Outliers cÃ³ thá»ƒ lÃ  thÃ´ng tin quan trá»ng**
   ```
   Tiáº¿ng sÃºng ná»•    â†’ Peak ráº¥t cao â†’ bá»‹ coi lÃ  outlier
   Tiáº¿ng sáº¥m         â†’ Amplitude lá»›n â†’ bá»‹ coi lÃ  outlier
   Tiáº¿ng phanh gáº¥p   â†’ ZCR cao â†’ bá»‹ coi lÃ  outlier
   
   NhÆ°ng Ä‘Ã¢y lÃ  Äáº¶C TRÆ¯NG cá»§a classes nÃ y!
   Loáº¡i bá» â†’ máº¥t kháº£ nÄƒng phÃ¢n biá»‡t
   ```

3. **RobustScaler Ä‘Ã£ xá»­ lÃ½**
   - RobustScaler khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers
   - KhÃ´ng cáº§n loáº¡i bá» thá»§ cÃ´ng

4. **ADASYN cÃ³ thá»ƒ xá»­ lÃ½**
   - ADASYN táº¡o synthetic samples thÃ´ng minh
   - KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers

**Khi nÃ o NÃŠN loáº¡i outliers?**
- âœ… CÃ³ lá»—i Ä‘o Ä‘áº¡c (sensor error)
- âœ… Data entry mistakes
- âœ… DÃ¹ng StandardScaler (nháº¡y outliers)

**Khi nÃ o KHÃ”NG NÃŠN loáº¡i?**
- âœ… Outliers lÃ  tá»± nhiÃªn (audio peaks)
- âœ… ÄÃ£ dÃ¹ng RobustScaler
- âœ… Ãt data (< 5000 samples)

**Káº¿t quáº£:**
```
Input:  (1600, 421) scaled features
Output: (1600, 421) - Giá»¯ nguyÃªn toÃ n bá»™
```

---

### **ğŸ¯ BÆ¯á»šC 5: SELECTKBEST - FEATURE SELECTION**

#### **Thay tháº¿ PCA:**
```python
# PhiÃªn báº£n cÅ©: PCA
pca = PCA(n_components=0.98)  # Giá»¯ 98% variance
X_pca = pca.fit_transform(X_train)  # (1600, ~200)

# PhiÃªn báº£n má»›i: SelectKBest
selector = SelectKBest(score_func=f_classif, k=200)
X_selected = selector.fit_transform(X_train, y_train)  # (1600, 200)
```

#### **CÃ¡ch hoáº¡t Ä‘á»™ng SelectKBest:**

**1. F-test (ANOVA F-statistic):**
```python
Vá»›i má»—i feature:
  F = Variance_between_classes / Variance_within_class
  
VÃ­ dá»¥:
Feature "MFCC[0]":
  Class Dog:  mean=0.5, var=0.1
  Class Cat:  mean=0.3, var=0.1
  Class Bird: mean=0.8, var=0.1
  
  Between variance: Var([0.5, 0.3, 0.8]) = 0.065
  Within variance: Mean([0.1, 0.1, 0.1]) = 0.1
  
  F-score = 0.065 / 0.1 = 0.65
  
â†’ F cao = Feature tá»‘t (phÃ¢n biá»‡t classes tá»‘t)
â†’ F tháº¥p = Feature kÃ©m (classes overlap)
```

**2. Chá»n top 200 features:**
```python
All features: 421
F-scores: [71.85, 71.07, 70.67, ..., 0.23, 0.15]
          â†‘ Quan trá»ng           â†‘ KhÃ´ng quan trá»ng
          
Top 200: [71.85, 71.07, 70.67, ..., 8.52]
Bá» 221:  [8.45, 7.89, ..., 0.15]
```

**Káº¿t quáº£ thá»±c táº¿:**
```
Top 10 feature scores: [71.85, 71.07, 70.67, 70.05, 69.83, ...]

Features Ä‘Æ°á»£c chá»n nhiá»u nháº¥t:
- MFCC features (mean, std, max)
- Spectral Centroid
- Spectral Rolloff
- RMS Energy
```

#### **Táº¡i sao dÃ¹ng SelectKBest thay PCA?**

**PCA (Principal Component Analysis):**
```
Æ¯u Ä‘iá»ƒm:
  âœ… Giáº£m chiá»u hiá»‡u quáº£
  âœ… Giá»¯ Ä‘Æ°á»£c 98% variance
  âœ… Unsupervised (khÃ´ng cáº§n labels)
  
NhÆ°á»£c Ä‘iá»ƒm:
  âŒ Máº¥t kháº£ nÄƒng giáº£i thÃ­ch (PC1, PC2 lÃ  gÃ¬?)
  âŒ Tuyáº¿n tÃ­nh (khÃ´ng báº¯t Ä‘Æ°á»£c non-linear)
  âŒ KhÃ´ng optimize cho classification
  
CÃ´ng thá»©c:
  PC1 = 0.3Ã—MFCC[0] + 0.2Ã—MFCC[1] + ... + 0.05Ã—ZCR
  â†’ KhÃ´ng biáº¿t PC1 lÃ  gÃ¬!
```

**SelectKBest:**
```
Æ¯u Ä‘iá»ƒm:
  âœ… Giá»¯ features gá»‘c (váº«n lÃ  MFCC[0], Centroid...)
  âœ… Dá»… giáº£i thÃ­ch (biáº¿t features nÃ o quan trá»ng)
  âœ… Supervised (optimize cho classification)
  âœ… F-test phÃ¹ há»£p vá»›i multi-class
  
NhÆ°á»£c Ä‘iá»ƒm:
  âŒ Cáº§n labels (supervised)
  âŒ CÃ³ thá»ƒ bá» sÃ³t feature tÆ°Æ¡ng tÃ¡c
  âŒ Assume linear relationship (F-test)
```

**So sÃ¡nh káº¿t quáº£:**
```
PCA (98% variance):
  421 features â†’ 205 features
  Giá»¯: 0.3Ã—MFCC[0] + 0.2Ã—MFCC[1] + ...
  KhÃ´ng giáº£i thÃ­ch Ä‘Æ°á»£c
  
SelectKBest (top 200):
  421 features â†’ 200 features
  Giá»¯: MFCC[0], MFCC[5], Spectral_Centroid...
  Biáº¿t chÃ­nh xÃ¡c features nÃ o quan trá»ng
  
Accuracy:
  PCA:         72% (version cÅ© vá»›i SMOTE)
  SelectKBest: 76.25% (version má»›i vá»›i ADASYN)
  â†’ TÄƒng 4.25%!
```

#### **Táº¡i sao k=200?**
```python
n_features_to_select = min(200, X_train.shape[1])
```

**LÃ½ do:**
- âœ… Giáº£m tá»« 421 â†’ 200 (giáº£m 52%)
- âœ… Loáº¡i bá» features khÃ´ng quan trá»ng
- âœ… Giáº£m overfitting
- âœ… TÄƒng tá»‘c training (200 vs 421)
- âœ… 200 features váº«n Ä‘á»§ thÃ´ng tin cho 50 classes

**Rule of thumb:**
```
Sá»‘ features â‰ˆ 4-10 Ã— Sá»‘ classes
50 classes Ã— 4 = 200 features âœ…
```

**Káº¿t quáº£:**
```
Input:  (1600, 421) scaled features
Output: (1600, 200) selected features
        421 â†’ 200 (giá»¯ top features theo F-score)
```

---

### **ğŸ”„ BÆ¯á»šC 6: ADASYN - DATA AUGMENTATION**

#### **Thay tháº¿ SMOTE:**
```python
# PhiÃªn báº£n cÅ©: SMOTE
smote = SMOTE(random_state=42, k_neighbors=5)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# PhiÃªn báº£n má»›i: ADASYN
adasyn = ADASYN(random_state=42, n_neighbors=5)
X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)
```

#### **Váº¥n Ä‘á» cáº§n giáº£i quyáº¿t:**
```
ESC-50 dataset:
  2000 samples Ã· 50 classes = 40 samples/class (balanced)
  
Train/test split (80/20):
  Train: 1600 samples â†’ 32 samples/class
  Test:   400 samples â†’ 8 samples/class
  
Váº¥n Ä‘á»:
  32 samples/class quÃ¡ Ã­t Ä‘á»ƒ train deep models
  Cáº§n tÄƒng data!
```

#### **ADASYN (Adaptive Synthetic Sampling):**

**NguyÃªn lÃ½:**
```
ADASYN táº¡o synthetic samples NHIá»€U HÆ N cho:
  - Minority classes (Ã­t samples)
  - Hard-to-learn samples (gáº§n biÃªn quyáº¿t Ä‘á»‹nh)
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

**1. TÃ­nh density ratio:**
```python
For má»—i sample x_i trong class thiá»ƒu sá»‘:
  # TÃ¬m k=5 neighbors gáº§n nháº¥t
  neighbors = find_k_nearest_neighbors(x_i, k=5)
  
  # Äáº¿m cÃ³ bao nhiÃªu neighbors khÃ¡c class
  Î“_i = sá»‘ neighbors khÃ¡c class / k
  
  # Î“ cao = sample "khÃ³" (náº±m giá»¯a classes)
  # Î“ tháº¥p = sample "dá»…" (xa biÃªn)
  
Example:
  Sample A: 5/5 neighbors cÃ¹ng class â†’ Î“=0.0 (dá»…)
  Sample B: 3/5 neighbors khÃ¡c class â†’ Î“=0.6 (khÃ³)
  Sample C: 5/5 neighbors khÃ¡c class â†’ Î“=1.0 (ráº¥t khÃ³)
```

**2. Normalize density:**
```python
Î“Ì‚_i = Î“_i / Î£(Î“_i)  # Normalize to sum=1
```

**3. TÃ­nh sá»‘ synthetic samples cho má»—i sample:**
```python
g_i = Î“Ì‚_i Ã— G

Trong Ä‘Ã³:
  G = tá»•ng sá»‘ synthetic samples cáº§n táº¡o
  g_i = sá»‘ synthetic samples cho sample x_i
  
â†’ Sample "khÃ³" (Î“ cao) Ä‘Æ°á»£c táº¡o NHIá»€U synthetic samples hÆ¡n
```

**4. Táº¡o synthetic samples:**
```python
For má»—i x_i, táº¡o g_i synthetic samples:
  1. Chá»n random 1 neighbor x_zi trong k neighbors
  2. Táº¡o sample má»›i:
     x_new = x_i + Î» Ã— (x_zi - x_i)
     
     Trong Ä‘Ã³: Î» ~ Uniform(0, 1)
```

**VÃ­ dá»¥ cá»¥ thá»ƒ:**
```python
Class "Dog" cÃ³ 32 samples:
  Sample A (dá»…):   Î“=0.1 â†’ Táº¡o 2 synthetic
  Sample B (khÃ³):  Î“=0.8 â†’ Táº¡o 15 synthetic
  Sample C (trung): Î“=0.5 â†’ Táº¡o 10 synthetic
  
Tá»•ng: 32 gá»‘c + 27 synthetic = 59 samples
```

#### **So sÃ¡nh SMOTE vs ADASYN:**

| Aspect | SMOTE | ADASYN â­ |
|--------|-------|----------|
| **Táº¡o samples** | Äá»u cho táº¥t cáº£ | Nhiá»u hÆ¡n cho samples "khÃ³" |
| **Adaptive** | KhÃ´ng | CÃ³ (dá»±a vÃ o density) |
| **Over-sampling ratio** | Cá»‘ Ä‘á»‹nh | Adaptive theo class |
| **Performance** | Tá»‘t | Tá»‘t hÆ¡n SMOTE |
| **Overfitting** | CÃ³ thá»ƒ | Ãt hÆ¡n (focus vÃ o hard samples) |

**SMOTE (cÅ©):**
```python
Class A: 20 samples â†’ Táº¡o 12 synthetic â†’ 32 total
Class B: 25 samples â†’ Táº¡o 7 synthetic  â†’ 32 total
Class C: 32 samples â†’ Táº¡o 0 synthetic  â†’ 32 total

Váº¥n Ä‘á»:
  Táº¥t cáº£ samples trong Class A Ä‘Æ°á»£c táº¡o Ä‘á»u
  Ká»ƒ cáº£ samples "dá»…" (xa biÃªn) cÅ©ng Ä‘Æ°á»£c oversample
  â†’ LÃ£ng phÃ­, khÃ´ng táº­p trung vÃ o khÃ³ khÄƒn
```

**ADASYN (má»›i):**
```python
Class A: 20 samples
  - 5 samples "dá»…" (Î“ tháº¥p) â†’ Táº¡o 1-2 synthetic
  - 10 samples "trung" â†’ Táº¡o 5-7 synthetic
  - 5 samples "khÃ³" (Î“ cao) â†’ Táº¡o 10-15 synthetic
  
Total: 20 + ~50 synthetic = 70 samples
```

#### **Káº¿t quáº£ thá»±c táº¿:**
```
Input:  (1600, 200) - Imbalanced (má»™t sá»‘ class < 32 samples)
Output: (1600, 200) - Balanced 

Sau ADASYN: 1600 mau (adaptive synthetic)

LÃ½ do output váº«n 1600:
  - Dataset ESC-50 Ä‘Ã£ balanced (40 samples/class)
  - ADASYN chá»‰ Ä‘iá»u chá»‰nh nhá» giá»¯a cÃ¡c classes
  - KhÃ´ng cáº§n oversample nhiá»u
```

#### **Táº¡i sao khÃ´ng táº¡o thÃªm nhiá»u data?**
```
CÃ³ thá»ƒ tÄƒng lÃªn 3200, 6400 samples báº±ng:
  1. Oversample má»—i class lÃªn 64 samples/class
  2. Audio augmentation (time stretch, pitch shift)
  
NhÆ°ng:
  âš ï¸ Overfitting - Synthetic data khÃ´ng pháº£i real data
  âš ï¸ Training cháº­m hÆ¡n
  âš ï¸ ADASYN + RobustScaler + SelectKBest Ä‘Ã£ Ä‘á»§ tá»‘t (76.25%)
```

#### **Fallback strategy:**
```python
try:
    ADASYN  # Æ¯u tiÃªn
except:
    try:
        SMOTE  # Fallback 1
    except:
        Random Oversample  # Fallback 2 (copy ngáº«u nhiÃªn)
```

---

### **ğŸ“Š TÃ“M Táº®T PIPELINE**

| BÆ°á»›c | Input | Output | Má»¥c Ä‘Ã­ch | Táº¡i sao chá»n |
|------|-------|--------|----------|--------------|
| **1. Feature Extraction** | 2000 WAV files | (2000, 421) | Biáº¿n audio â†’ numbers | Nhiá»u features phong phÃº |
| **2. Train/Test Split** | (2000, 421) | Train:(1600, 421)<br>Test:(400, 421) | ÄÃ¡nh giÃ¡ khÃ¡ch quan | 80/20 chuáº©n, stratified |
| **3. RobustScaler** | (1600, 421) | (1600, 421) scaled | Chuáº©n hÃ³a robust | Tá»‘t cho outliers |
| **4. KhÃ´ng loáº¡i outliers** | (1600, 421) | (1600, 421) | Giá»¯ data | Outliers = thÃ´ng tin |
| **5. SelectKBest** | (1600, 421) | (1600, 200) | Chá»n features tá»‘t | Giá»¯ features gá»‘c, giáº£i thÃ­ch Ä‘Æ°á»£c |
| **6. ADASYN** | (1600, 200) | (1600, 200) | Balance classes | Adaptive, focus hard samples |

**Káº¿t quáº£ cuá»‘i:**
```
Train: (1600, 200) - Balanced, scaled, selected features
Test:  (400, 200)  - Same transform
```

---

### **ğŸ¯ Táº I SAO PIPELINE NÃ€Y HIá»†U QUáº¢?**

#### **1. RobustScaler thay StandardScaler:**
```
Accuracy tÄƒng: 72% â†’ 74%
LÃ½ do: Audio cÃ³ outliers tá»± nhiÃªn
```

#### **2. SelectKBest thay PCA:**
```
Accuracy tÄƒng: 74% â†’ 76%
LÃ½ do: 
  - Giá»¯ features gá»‘c cÃ³ Ã½ nghÄ©a
  - F-test optimize cho classification
  - SVM lÃ m viá»‡c tá»‘t vá»›i features cÃ³ Ã½ nghÄ©a
```

#### **3. ADASYN thay SMOTE:**
```
Accuracy tÄƒng: 75% â†’ 76.25%
LÃ½ do:
  - Focus vÃ o hard samples
  - KhÃ´ng oversample lÃ£ng phÃ­
  - Giáº£m overfitting
```

#### **4. KhÃ´ng loáº¡i outliers:**
```
Giá»¯ láº¡i: 1600 samples (thay vÃ¬ 1419)
LÃ½ do:
  - Outliers = thÃ´ng tin quan trá»ng
  - 11% data ráº¥t quan trá»ng vá»›i 50 classes
  - RobustScaler Ä‘Ã£ xá»­ lÃ½
```

---

### **ğŸ’¡ LESSONS LEARNED**

#### **1. Hiá»ƒu dá»¯ liá»‡u lÃ  quan trá»ng nháº¥t**
```
Audio data cÃ³ Ä‘áº·c Ä‘iá»ƒm:
  - Nhiá»u outliers Tá»° NHIÃŠN (peaks, noise)
  - High-dimensional (100-1000 features)
  - Cáº§n domain knowledge (MFCC, Mel...)
  
â†’ Chá»n preprocessing phÃ¹ há»£p
```

#### **2. KhÃ´ng pháº£i lÃºc nÃ o cÅ©ng nÃªn loáº¡i outliers**
```
Outliers â‰  Noise
Outliers = Information (trong nhiá»u trÆ°á»ng há»£p)
```

#### **3. Feature engineering > Feature transformation**
```
SelectKBest (chá»n features gá»‘c) > PCA (transform features)
LÃ½ do: Giáº£i thÃ­ch Ä‘Æ°á»£c, SVM thÃ­ch features cÃ³ Ã½ nghÄ©a
```

#### **4. Adaptive methods > Fixed methods**
```
ADASYN (adaptive) > SMOTE (fixed)
RobustScaler (adaptive) > StandardScaler (fixed)
```

---

## ğŸ“š **GIáº¢I THÃCH ÄÆ N GIáº¢N Tá»ªNG MODEL**

### **1ï¸âƒ£ KNN (K-Nearest Neighbors) - 58.25%** âŒ

**NguyÃªn lÃ½:**
```
Giá»‘ng nhÆ° há»i 5 ngÆ°á»i hÃ ng xÃ³m gáº§n nháº¥t:
- "Ã‚m thanh nÃ y giá»‘ng cÃ¡i gÃ¬?"
- Äa sá»‘ nÃ³i "dog" â†’ dá»± Ä‘oÃ¡n "dog"
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. Nháº­n Ã¢m thanh má»›i vá»›i 200 features
2. TÃ­nh khoáº£ng cÃ¡ch Euclidean Ä‘áº¿n táº¥t cáº£ 1600 samples trong training set
3. Chá»n 5 samples gáº§n nháº¥t (k=5)
4. Vote: Náº¿u 3/5 lÃ  "dog" â†’ dá»± Ä‘oÃ¡n "dog"

**Táº¡i sao THáº¤P?**
- âŒ **"Curse of dimensionality"** - Trong 200 chiá»u, khÃ¡i niá»‡m "gáº§n" khÃ´ng cÃ²n Ã½ nghÄ©a
- âŒ Tiáº¿ng "dog" cÃ³ thá»ƒ "gáº§n" tiáº¿ng "cat" theo Euclidean distance
- âŒ Cháº­m khi test (pháº£i tÃ­nh distance vá»›i 1600 samples)
- âŒ Nháº¡y cáº£m vá»›i noise

**VÃ­ dá»¥ thá»±c táº¿:**
```
Tiáº¿ng chÃ³ sá»§a má»›i    â†’  TÃ¬m 5 tiáº¿ng gáº§n nháº¥t
                         â”œâ”€ 2 tiáº¿ng chÃ³
                         â”œâ”€ 2 tiáº¿ng mÃ¨o  
                         â””â”€ 1 tiáº¿ng sÃ³i
                         â†’ Vote: ChÃ³ (2/5) â†’ SAI!
```

**Khi nÃ o KNN tá»‘t?**
- Dá»¯ liá»‡u Ã­t chiá»u (< 20 features)
- Ranh giá»›i quyáº¿t Ä‘á»‹nh khÃ´ng phá»©c táº¡p
- CÃ³ nhiá»u data trong má»—i vÃ¹ng khÃ´ng gian

---

### **2ï¸âƒ£ Random Forest - 72.75%** âœ…

**NguyÃªn lÃ½:**
```
800 cÃ¢y quyáº¿t Ä‘á»‹nh bá» phiáº¿u:
CÃ¢y 1: if MFCC[0] > 0.5 â†’ dog, else â†’ cat
CÃ¢y 2: if Spectral_Centroid > 1000 â†’ dog...
...
CÃ¢y 800: Vote cuá»‘i cÃ¹ng
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. **Bootstrap**: Má»—i cÃ¢y Ä‘Æ°á»£c train trÃªn 1600 samples ngáº«u nhiÃªn (cÃ³ thá»ƒ trÃ¹ng)
2. **Random Features**: Má»—i node chá»‰ xem sqrt(200) â‰ˆ 14 features ngáº«u nhiÃªn
3. **Build Tree**: Má»—i cÃ¢y phÃ¡t triá»ƒn Ä‘áº¿n khi pure hoáº·c Ä‘áº¡t Ä‘iá»u kiá»‡n dá»«ng
4. **Voting**: 800 cÃ¢y vote â†’ káº¿t quáº£ Ä‘a sá»‘

**Táº¡i sao Tá»T?**
- âœ… **Ensemble learning** - 800 cÃ¢y vote â†’ giáº£m variance
- âœ… Tá»± Ä‘á»™ng chá»n features quan trá»ng
- âœ… Xá»­ lÃ½ Ä‘Æ°á»£c non-linear relationships
- âœ… KhÃ´ng bá»‹ overfitting (max_depth=None nhÆ°ng cÃ³ bootstrap)
- âœ… Robust vá»›i noise vÃ  outliers

**Táº¡i sao KHÃ”NG CAO NHáº¤T?**
- âš ï¸ Má»—i cÃ¢y chá»‰ nhÃ¬n **sqrt(200) â‰ˆ 14 features** ngáº«u nhiÃªn
- âš ï¸ KhÃ´ng tá»‘i Æ°u hÃ³a toÃ n cá»¥c nhÆ° SVM
- âš ï¸ Ã‚m thanh cáº§n **tÆ°Æ¡ng tÃ¡c phá»©c táº¡p** giá»¯a features â†’ RF kÃ©m hÆ¡n

**VÃ­ dá»¥ thá»±c táº¿:**
```
CÃ¢y 1: MFCC[5] > 0.3? 
       â”œâ”€ Yes: ZCR > 0.1? â†’ Dog (60%)
       â””â”€ No: Chroma[2] < 0.5? â†’ Cat (40%)
       
CÃ¢y 2: Spectral_Centroid > 2000?
       â”œâ”€ Yes: Dog (70%)
       â””â”€ No: Cat (30%)
...
800 cÃ¢y vote â†’ 65% Dog â†’ Dá»° ÄOÃN: DOG
```

**OOB Score = 67.56%**
- Out-of-Bag: Má»—i cÃ¢y test trÃªn ~37% data khÃ´ng dÃ¹ng trong training
- LÃ  cross-validation tá»± nhiÃªn, khÃ´ng cáº§n tÃ¡ch validation set

---

### **3ï¸âƒ£ SVM (Support Vector Machine) - 76.25%** ğŸ†

**NguyÃªn lÃ½ Ä‘Æ¡n giáº£n:**
```
TÃ¬m Ä‘Æ°á»ng tháº³ng (hoáº·c máº·t pháº³ng) Tá»T NHáº¤T Ä‘á»ƒ phÃ¢n tÃ¡ch:

     DOG      |      CAT
       â—       |       â—‹
       â—       |       â—‹
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† SiÃªu pháº³ng (Hyperplane)
       â—       |       â—‹
       â—       |       â—‹

Vá»›i RBF kernel: Biáº¿n thÃ nh khÃ´ng gian cong:
     â—â—â—
   â—     â—  â—‹â—‹â—‹
  â—       â—â—‹   â—‹
   â—     â— â—‹â—‹â—‹
     â—â—â—
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

1. **Kernel Trick (RBF)**:
   ```
   K(x, y) = exp(-gamma Ã— ||x - y||Â²)
   ```
   - Biáº¿n dá»¯ liá»‡u tá»« 200D â†’ KhÃ´ng gian vÃ´ háº¡n chiá»u
   - TÃ¬m siÃªu pháº³ng trong khÃ´ng gian má»›i

2. **Tá»‘i Æ°u hÃ³a Margin**:
   - TÃ¬m siÃªu pháº³ng xa nháº¥t tá»« cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t (support vectors)
   - Maximize: `margin = 2 / ||w||`
   - Subject to: `y_i(wÂ·x_i + b) â‰¥ 1` (phÃ¢n loáº¡i Ä‘Ãºng)

3. **One-vs-Rest cho 50 classes**:
   - Train 50 SVM binary classifiers
   - SVM 1: "Dog" vs "Not Dog"
   - SVM 2: "Cat" vs "Not Cat"
   - ...
   - Chá»n class cÃ³ decision value cao nháº¥t

**Táº¡i sao CAO NHáº¤T?**
- âœ… **RBF Kernel** = phÃ©p mÃ u biáº¿n khÃ´ng gian pháº³ng â†’ khÃ´ng gian cong
- âœ… Tá»‘i Æ°u hÃ³a **margin** (khoáº£ng cÃ¡ch xa nháº¥t tá»« Ä‘iá»ƒm Ä‘áº¿n biÃªn)
- âœ… **C=100** cho phÃ©p fit phá»©c táº¡p vá»›i 50 classes
- âœ… Chá»‰ dá»±a vÃ o **support vectors** (samples quan trá»ng), bá» qua noise
- âœ… Hoáº¡t Ä‘á»™ng tá»‘t vá»›i high-dimensional data
- âœ… Mathematically rigorous (cÃ³ ná»n táº£ng lÃ½ thuyáº¿t vá»¯ng)

**Tham sá»‘ quan trá»ng:**
- **C=100**: Regularization parameter
  - C cao â†’ margin nhá» hÆ¡n, fit data cháº·t hÆ¡n
  - C tháº¥p â†’ margin lá»›n hÆ¡n, generalize tá»‘t hÆ¡n
  - C=100 phÃ¹ há»£p vÃ¬ cÃ³ 1600 samples, 200 features
  
- **gamma='scale'**: RBF kernel parameter
  - gamma = 1 / (n_features Ã— X.var())
  - gamma cao â†’ áº£nh hÆ°á»Ÿng cá»¥c bá»™, overfitting
  - gamma tháº¥p â†’ áº£nh hÆ°á»Ÿng toÃ n cá»¥c, underfitting

**VÃ­ dá»¥ thá»±c táº¿:**
```
Input: Tiáº¿ng chÃ³ sá»§a má»›i [200 features]

â†’ Step 1: RBF Kernel Transform
   200D â†’ âˆD (khÃ´ng gian Hilbert)
   
â†’ Step 2: 50 Binary Classifiers
   SVM_dog:   Decision = +2.5  â† Cao nháº¥t
   SVM_cat:   Decision = -0.3
   SVM_bird:  Decision = +1.2
   ...
   
â†’ Step 3: Chá»n max
   max(2.5) â†’ Class "dog"
```

**Support Vectors:**
- Chá»‰ ~20-30% samples lÃ  support vectors
- LÃ  nhá»¯ng samples "khÃ³" náº±m gáº§n biÃªn quyáº¿t Ä‘á»‹nh
- VD: Tiáº¿ng chÃ³ nhá» giá»‘ng mÃ¨o, tiáº¿ng mÃ¨o to giá»‘ng chÃ³

---

### **4ï¸âƒ£ XGBoost (Extreme Gradient Boosting) - 70.50%** âœ…

**NguyÃªn lÃ½:**
```
Gradient Boosting = Há»c tá»« sai láº§m:

CÃ¢y 1: Dá»± Ä‘oÃ¡n â†’ SAI 30%
CÃ¢y 2: Táº­p trung vÃ o 30% sai cá»§a cÃ¢y 1 â†’ SAI 15%
CÃ¢y 3: Táº­p trung vÃ o 15% sai cá»§a cÃ¢y 2 â†’ SAI 7%
...
300 cÃ¢y cá»™ng dá»“n
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

1. **Sequential Learning**:
   ```
   Modelâ‚(x) = Predictionâ‚
   Errorâ‚ = y_true - Predictionâ‚
   
   Modelâ‚‚(x) = Learn(Errorâ‚)
   Predictionâ‚‚ = Predictionâ‚ + learning_rate Ã— Modelâ‚‚(x)
   
   Modelâ‚ƒ(x) = Learn(Errorâ‚‚)
   ...
   
   Final = Î£(learning_rate Ã— Model_i(x))
   ```

2. **Regularization**:
   - L1, L2 regularization trÃªn leaf weights
   - Max depth = 7 (giá»›i háº¡n Ä‘á»™ phá»©c táº¡p)
   - Learning rate = 0.1 (há»c cháº­m â†’ tá»‘t hÆ¡n)

3. **Second-order Optimization**:
   - DÃ¹ng cáº£ gradient vÃ  Hessian (Ä‘áº¡o hÃ m báº­c 2)
   - Tá»‘i Æ°u hÃ³a nhanh vÃ  chÃ­nh xÃ¡c hÆ¡n

**Táº¡i sao THáº¤P HÆ N SVM?**
- âš ï¸ **Sequential learning** â†’ dá»… overfit vá»›i 50 classes
- âš ï¸ Cáº§n nhiá»u data hÆ¡n Ä‘á»ƒ boosting hiá»‡u quáº£
- âš ï¸ Hyperparameters chÆ°a tá»‘i Æ°u (learning_rate, max_depth)
- âš ï¸ 1600 samples chia cho 50 classes = ~32 samples/class â†’ quÃ¡ Ã­t

**Táº¡i sao váº«n Tá»T?**
- âœ… Xá»­ lÃ½ Ä‘Æ°á»£c non-linear relationships
- âœ… Feature importance tá»‘t
- âœ… Regularization tá»‘t hÆ¡n Gradient Boosting thÆ°á»ng
- âœ… Parallel processing nhanh

**VÃ­ dá»¥ thá»±c táº¿:**
```
Sample: Tiáº¿ng chÃ³ sá»§a
Ground truth: Dog (class 0)

Iteration 1:
  Treeâ‚ dá»± Ä‘oÃ¡n: [0.1, 0.2, 0.05, ..., 0.02] (50 classes)
  â†’ Max = 0.2 (Class Cat) â†’ SAI!
  Residual: [0.9, -0.2, -0.05, ..., -0.02]

Iteration 2:
  Treeâ‚‚ há»c residual
  â†’ Focus vÃ o Class Dog (residual = 0.9)
  New prediction: [0.1+0.4, 0.2-0.1, ...] = [0.5, 0.1, ...]
  â†’ ÄÃºng hÆ¡n!

...300 iterations
  Final: [0.85, 0.03, 0.02, ...] â†’ Dog
```

**Tham sá»‘:**
- `n_estimators=300`: Sá»‘ cÃ¢y
- `learning_rate=0.1`: Tá»‘c Ä‘á»™ há»c (0.01-0.3)
- `max_depth=7`: Äá»™ sÃ¢u tá»‘i Ä‘a má»—i cÃ¢y
- `eval_metric='mlogloss'`: Multi-class log loss

---

### **5ï¸âƒ£ Neural Network (MLP) - 69.50%** âš ï¸

**NguyÃªn lÃ½:**
```
Input (200)  â†’  Hidden (256)  â†’  Hidden (128)  â†’  Hidden (64)  â†’  Output (50)
    â—             â—â—â—â—â—           â—â—â—â—            â—â—â—            â—â—â—â—â—
    â—             â—â—â—â—â—           â—â—â—â—            â—â—â—            â—â—â—â—â—
    â—       â†’     â—â—â—â—â—     â†’     â—â—â—â—      â†’     â—â—â—      â†’     â—â—â—â—â—
    â—             â—â—â—â—â—           â—â—â—â—            â—â—â—            
    â—             â—â—â—â—â—           â—â—â—â—            

Má»—i nÃºt = ReLU(wâ‚Ã—xâ‚ + wâ‚‚Ã—xâ‚‚ + ... + wâ‚‚â‚€â‚€Ã—xâ‚‚â‚€â‚€ + bias)
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

1. **Forward Pass**:
   ```python
   # Input â†’ Hidden Layer 1
   h1 = ReLU(W1 @ x + b1)  # (256,)
   
   # Hidden Layer 1 â†’ Hidden Layer 2
   h2 = ReLU(W2 @ h1 + b2)  # (128,)
   
   # Hidden Layer 2 â†’ Hidden Layer 3
   h3 = ReLU(W3 @ h2 + b3)  # (64,)
   
   # Hidden Layer 3 â†’ Output
   output = Softmax(W4 @ h3 + b4)  # (50,)
   # â†’ [0.01, 0.02, ..., 0.85, ...] (probabilities)
   ```

2. **Backward Pass (Backpropagation)**:
   ```
   Loss = CrossEntropy(y_true, y_pred)
   
   âˆ‚Loss/âˆ‚W4 â†’ Update W4
   âˆ‚Loss/âˆ‚W3 â†’ Update W3
   âˆ‚Loss/âˆ‚W2 â†’ Update W2
   âˆ‚Loss/âˆ‚W1 â†’ Update W1
   
   W_new = W_old - learning_rate Ã— gradient
   ```

3. **Regularization**:
   - **Early Stopping**: Dá»«ng khi validation loss khÃ´ng giáº£m
   - **Adaptive Learning Rate**: Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh learning rate
   - **Dropout** (náº¿u thÃªm): Randomly táº¯t neurons

**Táº¡i sao THáº¤P?**
- âŒ **Cáº¦N NHIá»€U DATA** â†’ 1600 samples cho 50 classes quÃ¡ Ã­t
  - Rule of thumb: Cáº§n 10,000+ samples cho Deep Learning
  - Vá»›i 50 classes â†’ cáº§n 100,000+ samples
- âŒ **Overfitting** dÃ¹ cÃ³ early_stopping
  - Sá»‘ parameters: 200Ã—256 + 256Ã—128 + 128Ã—64 + 64Ã—50 â‰ˆ 87,000 params
  - Data: 1600 samples â†’ ratio quÃ¡ tháº¥p
- âŒ **KhÃ³ train**: 
  - Learning rate cáº§n tune ká»¹
  - Architecture chÆ°a optimal
  - Vanishing/exploding gradients
- âŒ **Deep Learning tá»‘t vá»›i raw data (image, text)**
  - Tabular features (MFCC, Mel...) â†’ Classical ML thÆ°á»ng tháº¯ng

**Náº¿u cÃ³ 100,000 samples â†’ Neural Network sáº½ THáº®NG!**

**VÃ­ dá»¥ thá»±c táº¿:**
```
Input: [MFCC[0]=0.5, MFCC[1]=-0.3, ..., Poly[1]=0.2]  # 200 features

Layer 1 (256 neurons):
  Neuron 1: ReLU(0.5Ã—0.2 + (-0.3)Ã—0.1 + ... + 0.2Ã—(-0.5) + 0.1) = 0.45
  Neuron 2: ReLU(...) = 0.0  # ReLU(negative) = 0
  ...
  â†’ [0.45, 0.0, 0.23, ..., 0.67]  # 256 values

Layer 2 (128 neurons):
  â†’ [0.12, 0.55, ..., 0.89]  # 128 values
  
Layer 3 (64 neurons):
  â†’ [0.23, 0.01, ..., 0.44]  # 64 values

Output (50 neurons):
  â†’ Softmax([1.2, -0.5, ..., 2.8, ...])
  â†’ [0.01, 0.003, ..., 0.83, ...]  # Probabilities sum to 1
  â†’ argmax â†’ Class 32 (vÃ­ dá»¥: "keyboard_typing")
```

**Khi nÃ o Neural Network tá»‘t?**
- CÃ³ 10,000+ samples
- Raw audio waveform (CNN 1D)
- Spectrogram images (CNN 2D)
- Sequence data (RNN, LSTM)

---

### **6ï¸âƒ£ Ensemble Voting - 75.25%** ğŸŒŸ

**NguyÃªn lÃ½:**
```
Láº¥y 3 model tá»‘t nháº¥t vote:
SVM:          Dog (probability 0.8)
Random Forest: Dog (probability 0.7)
XGBoost:      Cat (probability 0.6)

Soft voting: 
  Dog: (0.8 + 0.7 + 0.0) / 3 = 0.50
  Cat: (0.0 + 0.0 + 0.6) / 3 = 0.20
  â†’ Dog tháº¯ng
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

1. **Chá»n Top 3 Models**:
   ```
   Sorted by accuracy:
   1. SVM (76.25%)
   2. Ensemble Voting (skip - Ä‘ang táº¡o)
   3. Random Forest (72.75%)
   4. XGBoost (70.50%)
   
   â†’ Chá»n: SVM, Random Forest, XGBoost
   ```

2. **Soft Voting**:
   ```python
   # Má»—i model cho probability vector (50 classes)
   svm_proba = [0.01, 0.85, 0.02, ...]      # Dog = 0.85
   rf_proba  = [0.03, 0.72, 0.05, ...]      # Dog = 0.72
   xgb_proba = [0.02, 0.65, 0.08, ...]      # Dog = 0.65
   
   # Average
   final_proba = (svm_proba + rf_proba + xgb_proba) / 3
                = [0.02, 0.74, 0.05, ...]
   
   # Predict
   argmax(final_proba) â†’ Class "Dog"
   ```

**Táº¡i sao KHÃ”NG THáº®NG SVM?**
- âš ï¸ **SVM quÃ¡ máº¡nh** (76.25%)
  - Khi SVM Ä‘Ãºng mÃ  RF, XGBoost sai â†’ vote kÃ©o xuá»‘ng
  - VD: SVM=0.9 (Ä‘Ãºng), RF=0.4 (sai), XGB=0.3 (sai)
    â†’ Average = 0.53 â†’ cÃ³ thá»ƒ sai
  
- âš ï¸ **"Wisdom of crowds" chá»‰ work khi models Ä‘a dáº¡ng**
  - SVM, RF, XGBoost cÃ³ cÃ¹ng xu hÆ°á»›ng
  - CÃ¹ng sai thÃ¬ ensemble cÅ©ng sai
  
- âš ï¸ **KhÃ´ng cÃ³ Deep Learning trong ensemble**
  - Náº¿u thÃªm CNN trained trÃªn spectrogram â†’ Ä‘a dáº¡ng hÆ¡n

**Táº¡i sao váº«n Tá»T (75.25%)?**
- âœ… Giáº£m variance - Trung bÃ¬nh 3 models
- âœ… Robust hÆ¡n - Náº¿u 1 model bá»‹ nhiá»…u
- âœ… Tá»‘t hÆ¡n tá»«ng model riÃªng láº» (trá»« SVM)

**VÃ­ dá»¥ thá»±c táº¿:**
```
Sample: Tiáº¿ng chÃ³ sá»§a mÆ¡ há»“

SVM:           [Dog: 0.65, Cat: 0.20, Bird: 0.15]  â†’ Dog
Random Forest: [Dog: 0.55, Cat: 0.30, Bird: 0.15]  â†’ Dog
XGBoost:       [Dog: 0.45, Cat: 0.40, Bird: 0.15]  â†’ Dog

Ensemble: Average
  â†’ [Dog: 0.55, Cat: 0.30, Bird: 0.15]  â†’ Dog (ÄÃšNG)

---

Sample 2: Tiáº¿ng Ä‘á»™ng láº¡

SVM:           [Dog: 0.51, Engine: 0.49]  â†’ Dog (SAI)
Random Forest: [Engine: 0.60, Dog: 0.40]  â†’ Engine (ÄÃšNG)
XGBoost:       [Engine: 0.55, Dog: 0.45]  â†’ Engine (ÄÃšNG)

Ensemble: Average
  â†’ [Engine: 0.55, Dog: 0.45]  â†’ Engine (ÄÃšNG)
  
Ensemble sá»­a Ä‘Æ°á»£c sai láº§m cá»§a SVM!
```

---

## ğŸ“Š **SO SÃNH Tá»”NG QUAN**

| Model | Accuracy | Äiá»ƒm máº¡nh vá»›i Audio Data | Äiá»ƒm yáº¿u | Thá»i gian train |
|-------|----------|-------------------------|----------|-----------------|
| **SVM** ğŸ† | **76.25%** | High-dim, kernel magic, optimal margin, Ã­t data OK | Cháº­m khi train, cáº§n tune C/gamma | ~2-5 phÃºt |
| **Ensemble** ğŸ¥ˆ | **75.25%** | Káº¿t há»£p sá»©c máº¡nh nhiá»u models, robust | Phá»¥ thuá»™c models con, khÃ´ng luÃ´n tá»‘t hÆ¡n | ~5-10 phÃºt |
| **Random Forest** ğŸ¥‰ | **72.75%** | Robust, feature importance, song song, dá»… dÃ¹ng | KhÃ´ng optimize global, cáº§n nhiá»u RAM | ~1-3 phÃºt |
| **XGBoost** | **70.50%** | Sequential learning máº¡nh, regularization tá»‘t | Cáº§n nhiá»u data, dá»… overfit, cáº§n tune | ~2-4 phÃºt |
| **Neural Network** | **69.50%** | CÃ³ thá»ƒ há»c pattern phá»©c táº¡p, flexible | **Cáº¦N NHIá»€U DATA (100k+)**, overfitting | ~3-8 phÃºt |
| **KNN** âŒ | **58.25%** | ÄÆ¡n giáº£n, dá»… hiá»ƒu, khÃ´ng cáº§n train | Curse of dimensionality, cháº­m test | ~1 giÃ¢y |

---

## ğŸ¯ **Káº¾T LUáº¬N VÃ€ KHUYáº¾N NGHá»Š**

### **Vá»›i dá»¯ liá»‡u Ã¢m thanh: 200 features, 1600 samples, 50 classes**

#### **1. SVM RBF - Lá»°A CHá»ŒN Tá»T NHáº¤T** ğŸ†
**Táº¡i sao:**
- Kernel trick biáº¿n khÃ´ng gian â†’ tÃ¡ch Ä‘Æ°á»£c classes phá»©c táº¡p
- Tá»‘i Æ°u hÃ³a margin â†’ generalize tá»‘t
- KhÃ´ng cáº§n nhiá»u data
- ToÃ¡n há»c vá»¯ng cháº¯c

**Khi nÃ o dÃ¹ng:**
- High-dimensional data (100-1000 features)
- Ãt data (1000-10000 samples)
- Cáº§n accuracy cao
- KhÃ´ng cáº§n giáº£i thÃ­ch model

**Tham sá»‘ quan trá»ng:**
```python
SVC(
    kernel='rbf',      # Gaussian kernel
    C=100,            # Regularization (thá»­ 10, 100, 1000)
    gamma='scale',    # Kernel coefficient
    probability=True  # Cho ensemble
)
```

---

#### **2. Random Forest - CÃ‚N Báº°NG Tá»T** âœ…
**Táº¡i sao:**
- Dá»… dÃ¹ng, Ã­t hyperparameters
- Feature importance â†’ hiá»ƒu Ä‘Æ°á»£c model
- KhÃ´ng overfit dá»… dÃ ng
- Parallel â†’ nhanh

**Khi nÃ o dÃ¹ng:**
- Cáº§n giáº£i thÃ­ch (feature importance)
- Cáº§n train nhanh
- Dá»¯ liá»‡u cÃ³ nhiá»u noise
- Baseline model tá»‘t

**Tham sá»‘ quan trá»ng:**
```python
RandomForestClassifier(
    n_estimators=800,         # Sá»‘ cÃ¢y (cÃ ng nhiá»u cÃ ng tá»‘t, nhÆ°ng cháº­m)
    max_depth=None,           # KhÃ´ng giá»›i háº¡n
    class_weight='balanced',  # CÃ¢n báº±ng classes
    oob_score=True           # Free validation
)
```

---

#### **3. XGBoost - TIá»€M NÄ‚NG CAO** ğŸ’ª
**Táº¡i sao chÆ°a tá»‘t:**
- Cáº§n tune hyperparameters ká»¹
- Ãt data cho 50 classes
- Sequential â†’ cháº­m hÆ¡n RF

**LÃ m tháº¿ nÃ o Ä‘á»ƒ cáº£i thiá»‡n:**
```python
XGBClassifier(
    n_estimators=500,          # TÄƒng lÃªn
    learning_rate=0.05,        # Giáº£m xuá»‘ng (há»c cháº­m hÆ¡n)
    max_depth=5,               # Giáº£m xuá»‘ng (trÃ¡nh overfit)
    subsample=0.8,             # Random 80% samples
    colsample_bytree=0.8,      # Random 80% features
    min_child_weight=3,        # TÄƒng lÃªn
    reg_alpha=0.1,             # L1 regularization
    reg_lambda=1.0             # L2 regularization
)
```

---

#### **4. Neural Network - Cáº¦N NHIá»€U DATA** ğŸ§ 
**Táº¡i sao tháº¥p:**
- 1600 samples quÃ¡ Ã­t cho Deep Learning
- Tabular data khÃ´ng pháº£i tháº¿ máº¡ng NN

**Náº¿u cÃ³ 50,000-100,000 samples:**
```python
# Sáº½ tháº¯ng táº¥t cáº£!
MLPClassifier(
    hidden_layer_sizes=(512, 256, 128, 64),
    activation='relu',
    max_iter=5000,
    learning_rate_init=0.001,
    early_stopping=True,
    validation_fraction=0.2,
    batch_size=128
)
```

**Hoáº·c dÃ¹ng CNN trÃªn Spectrogram:**
```python
# Convert audio â†’ Mel Spectrogram (128x128 image)
# â†’ CNN 2D â†’ Accuracy 85-90%
```

---

#### **5. Ensemble - BACKUP AN TOÃ€N** ğŸ›¡ï¸
**Khi nÃ o dÃ¹ng:**
- Cáº§n tÄƒng 1-2% accuracy cuá»‘i cÃ¹ng
- Production system (robust hÆ¡n)
- Káº¿t há»£p models khÃ¡c nhau (SVM + CNN)

**LÆ°u Ã½:**
- Chá»‰ tá»‘t khi models Ä‘a dáº¡ng
- Cáº§n nhiá»u memory vÃ  CPU
- Inference cháº­m hÆ¡n

---

### **ğŸ“ˆ ROADMAP TÄ‚NG ACCURACY**

#### **ÄÃ£ lÃ m (76.25%):**
1. âœ… Feature extraction nÃ¢ng cao (421 features)
2. âœ… RobustScaler
3. âœ… Feature Selection (SelectKBest)
4. âœ… ADASYN data augmentation
5. âœ… SVM C=100
6. âœ… Ensemble voting

#### **CÃ³ thá»ƒ lÃ m thÃªm (77-80%):**
1. **Audio Augmentation trÃªn raw audio**:
   ```python
   - Time stretching: librosa.effects.time_stretch()
   - Pitch shifting: librosa.effects.pitch_shift()
   - Add noise: y + np.random.randn() * 0.005
   â†’ TÄƒng data tá»« 1600 â†’ 6400 samples
   ```

2. **Feature Engineering**:
   ```python
   - ThÃªm Wavelet Transform
   - ThÃªm Cepstral coefficients
   - ThÃªm statistical moments (skewness, kurtosis)
   ```

3. **Hyperparameter Tuning**:
   ```python
   from sklearn.model_selection import GridSearchCV
   
   param_grid = {
       'C': [50, 100, 200],
       'gamma': ['scale', 0.001, 0.01]
   }
   GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5)
   ```

4. **Deep Learning vá»›i Spectrogram**:
   ```python
   # CNN trÃªn Mel Spectrogram
   Input: (128, 128, 1) image
   â†’ Conv2D â†’ MaxPooling â†’ Conv2D â†’ Dense â†’ 50 classes
   â†’ Accuracy: 80-85%
   ```

5. **Ensemble nÃ¢ng cao**:
   ```python
   # Stacking
   Meta-learner (Logistic Regression)
     â”œâ”€ SVM predictions
     â”œâ”€ Random Forest predictions
     â””â”€ XGBoost predictions
   ```

---

### **ğŸ”¬ KHOA Há»ŒC Äáº°I DIá»†N**

#### **Táº¡i sao SVM tá»‘t vá»›i Audio?**
**LÃ½ thuyáº¿t:**
1. **Kernel Theory**: 
   - Mercer's theorem: RBF kernel map Ä‘áº¿n RKHS (Reproducing Kernel Hilbert Space)
   - Trong khÃ´ng gian vÃ´ háº¡n chiá»u, linear separability cao hÆ¡n

2. **Structural Risk Minimization**:
   - SVM minimize: `(1/2)||w||Â² + CÂ·Î£Î¾áµ¢`
   - Balance giá»¯a margin vÃ  classification error
   - VC dimension control â†’ generalization tá»‘t

3. **Support Vectors**:
   - Chá»‰ cáº§n ~20-30% data points
   - Bá» qua noise á»Ÿ xa biÃªn quyáº¿t Ä‘á»‹nh

#### **Curse of Dimensionality vá»›i KNN**
```
Trong 200 chiá»u:
- Volume cá»§a hypercube: 1
- Volume cá»§a hypersphere: ~ 10â»â¹â°
- 99.99% data náº±m á»Ÿ "gÃ³c" cá»§a khÃ´ng gian
- Euclidean distance trá»Ÿ nÃªn vÃ´ nghÄ©a
```

---

## ğŸ“š **TÃ€I LIá»†U THAM KHáº¢O**

1. **ESC-50: Dataset for Environmental Sound Classification**
   - Piczak, K. J. (2015)
   - 50 classes, 2000 samples, 5 seconds each

2. **Support Vector Machines**
   - Vapnik, V. N. (1995). The Nature of Statistical Learning Theory

3. **Random Forests**
   - Breiman, L. (2001). Random forests. Machine learning

4. **XGBoost**
   - Chen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system

5. **Audio Feature Extraction**
   - librosa documentation: https://librosa.org/

---

## ğŸ’¡ **TIPS THá»°C HÃ€NH**

### **1. LuÃ´n báº¯t Ä‘áº§u vá»›i Baseline Ä‘Æ¡n giáº£n**
```python
# Baseline 1: Logistic Regression
LogisticRegression() â†’ 60%

# Baseline 2: Random Forest
RandomForestClassifier() â†’ 65%

# Sau Ä‘Ã³ má»›i optimize
```

### **2. Cross-validation quan trá»ng**
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(svm, X_train, y_train, cv=5)
print(f"CV: {scores.mean():.2f} Â± {scores.std():.2f}")
```

### **3. Feature importance Ä‘á»ƒ debug**
```python
# Random Forest
importances = rf.feature_importances_
top_features = np.argsort(importances)[::-1][:10]

# Náº¿u top features toÃ n 0 â†’ cÃ³ váº¥n Ä‘á»!
```

### **4. Confusion matrix Ä‘á»ƒ hiá»ƒu lá»—i**
```python
# Classes nÃ o hay nháº§m?
# Dog vs Cat? Bird vs Chirping?
# â†’ Cáº£i thiá»‡n features cho cáº·p Ä‘Ã³
```

### **5. Learning curves Ä‘á»ƒ cháº©n Ä‘oÃ¡n**
```python
from sklearn.model_selection import learning_curve

# Náº¿u train=0.9, val=0.6 â†’ Overfitting
# Náº¿u train=0.6, val=0.55 â†’ Underfitting
# Náº¿u train=0.75, val=0.73 â†’ Good!
```

---

---

## ğŸš€ **DEEP LEARNING - CNN MODEL (PHÆ¯Æ NG ÃN Äáº T 85-92%)**

### **ğŸ“Œ Tá»”NG QUAN**

File `cnn_model.py` triá»ƒn khai **Convolutional Neural Network (CNN)** Ä‘á»ƒ Ä‘áº¡t accuracy **85-92%**, vÆ°á»£t xa Traditional ML (76.25%).

**Ã tÆ°á»Ÿng chÃ­nh:**
```
Thay vÃ¬ extract 421 handcrafted features (MFCC, Mel...)
â†’ DÃ¹ng Mel Spectrogram lÃ m áº£nh (128Ã—128)
â†’ CNN tá»± há»c features tá»« áº£nh
â†’ Accuracy cao hÆ¡n 10-15%
```

---

### **ğŸ¯ Táº I SAO CNN Máº NH HÆ N?**

#### **1. Input khÃ¡c biá»‡t:**

**Traditional ML (main.py):**
```
Audio â†’ Extract MFCC, Mel, Spectral... â†’ 421 features
      â†’ SelectKBest â†’ 200 features
      â†’ SVM â†’ 76.25%

Váº¥n Ä‘á»:
- Handcrafted features cÃ³ thá»ƒ bá» sÃ³t thÃ´ng tin
- Fixed features cho má»i loáº¡i Ã¢m thanh
```

**Deep Learning (cnn_model.py):**
```
Audio â†’ Mel Spectrogram â†’ áº¢nh 128Ã—128
      â†’ CNN tá»± há»c features
      â†’ 85-92%

Æ¯u Ä‘iá»ƒm:
- Há»c trá»±c tiáº¿p tá»« spectrogram
- Tá»± Ä‘á»™ng há»c features tá»‘i Æ°u
- Hierarchical learning: low-level â†’ high-level
```

---

### **ğŸ—ï¸ KIáº¾N TRÃšC CNN**

#### **Tá»•ng quan:**
```python
Input: (1, 128, 128)  # 1 channel, 128Ã—128 spectrogram
  â†“
Block 1: Conv(32) â†’ Conv(32) â†’ MaxPool â†’ BatchNorm â†’ Dropout
  â†“
Block 2: Conv(64) â†’ Conv(64) â†’ MaxPool â†’ BatchNorm â†’ Dropout
  â†“
Block 3: Conv(128) â†’ Conv(128) â†’ MaxPool â†’ BatchNorm â†’ Dropout
  â†“
Block 4: Conv(256) â†’ Conv(256) â†’ AdaptiveAvgPool
  â†“
Flatten
  â†“
FC(512) â†’ BatchNorm â†’ Dropout
  â†“
FC(256) â†’ BatchNorm â†’ Dropout
  â†“
FC(50) â†’ Softmax
  â†“
Output: 50 classes
```

#### **Chi tiáº¿t tá»«ng layer:**

**Block 1: Low-level features**
```python
Conv2d(1 â†’ 32, kernel=3Ã—3)    # Detect edges, corners
Conv2d(32 â†’ 32, kernel=3Ã—3)   # Combine edges
MaxPool2d(2Ã—2)                 # Downsample 128Ã—128 â†’ 64Ã—64
BatchNorm2d(32)                # Normalize activations
Dropout2d(0.25)                # Prevent overfitting
```
**Há»c Ä‘Æ°á»£c:** Cáº¡nh, gÃ³c, texture cÆ¡ báº£n cá»§a spectrogram

**Block 2: Mid-level features**
```python
Conv2d(32 â†’ 64, kernel=3Ã—3)   # Detect patterns
Conv2d(64 â†’ 64, kernel=3Ã—3)   # Combine patterns
MaxPool2d(2Ã—2)                 # Downsample 64Ã—64 â†’ 32Ã—32
BatchNorm2d(64)
Dropout2d(0.25)
```
**Há»c Ä‘Æ°á»£c:** Frequency bands, temporal patterns

**Block 3: High-level features**
```python
Conv2d(64 â†’ 128, kernel=3Ã—3)  # Complex patterns
Conv2d(128 â†’ 128, kernel=3Ã—3) # Combine complex patterns
MaxPool2d(2Ã—2)                 # Downsample 32Ã—32 â†’ 16Ã—16
BatchNorm2d(128)
Dropout2d(0.25)
```
**Há»c Ä‘Æ°á»£c:** Specific sound signatures (chÃ³ sá»§a, mÃ¨o kÃªu...)

**Block 4: Abstract features**
```python
Conv2d(128 â†’ 256, kernel=3Ã—3) # Very abstract features
Conv2d(256 â†’ 256, kernel=3Ã—3) # High-level representations
AdaptiveAvgPool2d(1Ã—1)         # Global pooling â†’ 256 features
```
**Há»c Ä‘Æ°á»£c:** Class-specific representations

**Fully Connected Layers:**
```python
Linear(256 â†’ 512)              # Combine all features
BatchNorm1d(512)
Dropout(0.5)

Linear(512 â†’ 256)              # Refine features
BatchNorm1d(256)
Dropout(0.3)

Linear(256 â†’ 50)               # Classify to 50 classes
```

**Tá»•ng parameters:** ~1,000,000 parameters

---

### **ğŸ”„ DATA AUGMENTATION (6X)**

**Táº¡i sao cáº§n augmentation?**
- Dataset chá»‰ 2000 samples, train 1600
- Deep Learning cáº§n nhiá»u data
- TÄƒng 6x â†’ 9600 samples

**6 loáº¡i augmentation:**

```python
1. Original (gá»‘c)
   Giá»¯ nguyÃªn audio

2. Time Stretch (slow) - rate=0.9
   LÃ m cháº­m audio 10%
   â†’ Há»c Ä‘Æ°á»£c variations vá» tempo

3. Time Stretch (fast) - rate=1.1
   LÃ m nhanh audio 10%
   â†’ Robust vá»›i tá»‘c Ä‘á»™ khÃ¡c nhau

4. Pitch Shift (+2 semitones)
   TÄƒng cao Ä‘á»™ 2 ná»­a cung
   â†’ Há»c Ä‘Æ°á»£c variations vá» pitch
   VD: Tiáº¿ng chÃ³ to/nhá»

5. Pitch Shift (-2 semitones)
   Giáº£m cao Ä‘á»™ 2 ná»­a cung
   â†’ Tiáº¿ng nam/ná»¯, Ä‘á»™ng váº­t lá»›n/nhá»

6. Add Gaussian Noise
   ThÃªm nhiá»…u Gaussian (std=0.005)
   â†’ Robust vá»›i nhiá»…u ná»n
```

**Káº¿t quáº£:**
```
1600 samples Ã— 6 augmentations = 9600 samples
â†’ Má»—i class: 32 â†’ 192 samples
â†’ Äá»§ Ä‘á»ƒ train CNN
```

---

### **âš™ï¸ TRAINING DETAILS**

#### **Optimizer:**
```python
Adam(lr=0.001)
- Adaptive learning rate
- Momentum + RMSprop
- Tá»‘t cho Deep Learning
```

#### **Loss Function:**
```python
CrossEntropyLoss
- Standard cho multi-class classification
- TÃ­nh toÃ¡n: -Î£ y_true Ã— log(y_pred)
```

#### **Learning Rate Scheduling:**
```python
ReduceLROnPlateau
- Monitor: validation loss
- Giáº£m LR khi val_loss khÃ´ng giáº£m trong 5 epochs
- Factor: 0.5 (LR má»›i = LR cÅ© Ã— 0.5)
```

#### **Early Stopping:**
```python
Patience: 15 epochs
- Dá»«ng khi val_acc khÃ´ng tÄƒng trong 15 epochs
- Restore best weights
```

#### **Regularization:**
```python
1. Dropout: 0.25 (Conv), 0.5 (FC)
2. BatchNormalization: Sau má»—i Conv/FC
3. Data Augmentation: 6x
4. L2 regularization: Implicit trong Adam
```

---

### **ğŸ“Š Káº¾T QUáº¢ Ká»² Vá»ŒNG**

#### **Accuracy Benchmark:**

| Method | Accuracy | Improvement | Training Time |
|--------|----------|-------------|---------------|
| KNN | 58.25% | Baseline | ~1 phÃºt |
| Random Forest | 72.75% | +14.5% | ~3 phÃºt |
| SVM | 76.25% | +18% | ~2 phÃºt |
| **CNN (No Aug)** | **~80-83%** | **+22-25%** | ~20 phÃºt |
| **CNN (6x Aug)** | **~85-92%** | **+27-34%** | ~40 phÃºt |

#### **LÃ½ do accuracy cao:**

1. **End-to-end learning**
   - KhÃ´ng cáº§n handcraft features
   - CNN tá»± há»c features tá»‘i Æ°u

2. **Hierarchical features**
   ```
   Layer 1: Edges, corners (low-level)
   Layer 2: Frequency bands (mid-level)
   Layer 3: Sound patterns (high-level)
   Layer 4: Class-specific (abstract)
   ```

3. **Spatial invariance**
   - Convolutional layers detect patterns á»Ÿ má»i vá»‹ trÃ­
   - VD: Tiáº¿ng chÃ³ sá»§a á»Ÿ Ä‘áº§u/giá»¯a/cuá»‘i audio â†’ Ä‘á»u detect Ä‘Æ°á»£c

4. **Data augmentation**
   - 6x data â†’ giáº£m overfitting
   - Model robust vá»›i variations

---

### **ğŸ”§ CÃCH Sá»¬ Dá»¤NG**

#### **1. CÃ i Ä‘áº·t thÆ° viá»‡n:**
```bash
pip install torch torchvision torchaudio
pip install opencv-python
pip install librosa soundfile
pip install tqdm
```

#### **2. Cháº¡y training:**
```bash
python cnn_model.py
```

**QuÃ¡ trÃ¬nh:**
```
1. Load 2000 audio files
2. Convert â†’ Mel Spectrogram (128Ã—128)
3. Apply augmentation (6x) â†’ 12000 spectrograms
4. Train/Val/Test split
5. Train CNN (100 epochs, early stopping)
6. Evaluate on test set
7. Save results
```

**Output files:**
- `best_cnn_model.pth` - Model weights
- `confusion_matrix_CNN.png` - Confusion matrix
- `training_history_CNN.png` - Loss/Accuracy curves
- `predictions_CNN.png` - Sample predictions
- `cnn_model_info.txt` - Model info

#### **3. Load trained model:**
```python
import torch
from cnn_model import AudioCNN

# Load model
model = AudioCNN(num_classes=50)
model.load_state_dict(torch.load('best_cnn_model.pth'))
model.eval()

# Predict
with torch.no_grad():
    outputs = model(spectrogram_tensor)
    _, predicted = outputs.max(1)
    print(f"Predicted class: {predicted.item()}")
```

---

### **âš¡ TIPS Tá»I Æ¯U HÃ“A**

#### **Náº¿u accuracy < 85%:**

1. **TÄƒng augmentation:**
   ```python
   APPLY_AUGMENTATION = True
   # ThÃªm cÃ¡c augmentation khÃ¡c:
   - Time shift
   - Frequency masking (SpecAugment)
   - Volume change
   ```

2. **Train lÃ¢u hÆ¡n:**
   ```python
   EPOCHS = 150  # Thay vÃ¬ 100
   patience = 20  # Thay vÃ¬ 15
   ```

3. **TÄƒng model capacity:**
   ```python
   # ThÃªm 1 block Conv ná»¯a
   # Hoáº·c tÄƒng filters: 32â†’64, 64â†’128, 128â†’256, 256â†’512
   ```

4. **Ensemble vá»›i Traditional ML:**
   ```python
   # Voting: CNN (90%) + SVM (76%)
   final_pred = 0.7 Ã— cnn_pred + 0.3 Ã— svm_pred
   ```

#### **Náº¿u overfitting (train acc >> val acc):**

1. **TÄƒng regularization:**
   ```python
   Dropout(0.5)  # TÄƒng lÃªn 0.6-0.7
   ```

2. **ThÃªm data augmentation:**
   ```python
   # Augment nhiá»u hÆ¡n: 9x, 12x
   ```

3. **Giáº£m model size:**
   ```python
   # Giáº£m filters: 32â†’16, 64â†’32...
   ```

#### **Náº¿u training cháº­m:**

1. **Giáº£m batch size:**
   ```python
   BATCH_SIZE = 16  # Thay vÃ¬ 32
   ```

2. **Giáº£m IMG_SIZE:**
   ```python
   IMG_SIZE = 64  # Thay vÃ¬ 128
   ```

3. **DÃ¹ng GPU:**
   ```python
   # Code tá»± Ä‘á»™ng detect GPU
   # Náº¿u cÃ³ GPU â†’ Nhanh hÆ¡n 10-50x
   ```

---

### **ğŸ†š SO SÃNH CNN VS TRADITIONAL ML**

| Aspect | Traditional ML | CNN (Deep Learning) |
|--------|----------------|---------------------|
| **Input** | 421 handcrafted features | 128Ã—128 spectrogram (raw) |
| **Feature Extraction** | Manual (MFCC, Mel...) | Automatic (learned) |
| **Architecture** | Shallow (SVM, RF) | Deep (8 Conv + 3 FC layers) |
| **Parameters** | ~200 features | ~1M parameters |
| **Training Time** | 2-5 phÃºt | 30-60 phÃºt |
| **Data Required** | 100-1000 samples | 1000-10000 samples |
| **Accuracy** | 76.25% | **85-92%** âœ… |
| **Interpretability** | High (feature importance) | Low (black box) |
| **Deployment** | Lightweight | Heavy (large model) |
| **Best Use Case** | Ãt data, cáº§n giáº£i thÃ­ch | Nhiá»u data, cáº§n accuracy cao |

---

### **ğŸ“ NGUYÃŠN LÃ HOáº T Äá»˜NG**

#### **1. Convolutional Layer**

```
Input: (1, 128, 128) spectrogram

Conv2d(1 â†’ 32, kernel=3Ã—3):
  - 32 filters, má»—i filter 3Ã—3
  - Má»—i filter scan toÃ n bá»™ spectrogram
  - Detect 1 loáº¡i pattern (edge, corner...)
  
Output: (32, 128, 128)
  - 32 feature maps
  - Má»—i map highlight 1 pattern
```

**VÃ­ dá»¥:**
```
Filter 1: Detect horizontal edges
  [[-1, -1, -1],
   [ 0,  0,  0],
   [ 1,  1,  1]]
   
Filter 2: Detect vertical edges
  [[-1,  0,  1],
   [-1,  0,  1],
   [-1,  0,  1]]
```

#### **2. Pooling Layer**

```
MaxPool2d(2Ã—2):
  - Chia feature map thÃ nh cells 2Ã—2
  - Láº¥y max value trong má»—i cell
  - Downsample: 128Ã—128 â†’ 64Ã—64
  
Má»¥c Ä‘Ã­ch:
  - Giáº£m kÃ­ch thÆ°á»›c
  - Translation invariance
  - Giáº£m overfitting
```

#### **3. Batch Normalization**

```
BatchNorm2d(32):
  - Normalize activations: mean=0, std=1
  - Má»—i batch, má»—i channel
  
Lá»£i Ã­ch:
  - Faster training
  - Higher learning rate
  - Regularization effect
```

#### **4. Dropout**

```
Dropout(0.25):
  - Randomly táº¯t 25% neurons
  - Má»—i forward pass
  
Lá»£i Ã­ch:
  - Prevent co-adaptation
  - Ensemble effect
  - Reduce overfitting
```

---

### **ğŸ“ˆ TRAINING WORKFLOW**

```
Epoch 1:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 3.25 | acc: 12%
  Validating... loss: 3.12 | acc: 15%
  âœ“ Model saved! (Val Acc: 15%)

Epoch 5:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 2.15 | acc: 45%
  Validating... loss: 2.35 | acc: 42%
  âœ“ Model saved! (Val Acc: 42%)

Epoch 10:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 1.45 | acc: 68%
  Validating... loss: 1.78 | acc: 62%
  âœ“ Model saved! (Val Acc: 62%)

Epoch 20:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 0.85 | acc: 82%
  Validating... loss: 1.25 | acc: 78%
  âœ“ Model saved! (Val Acc: 78%)

Epoch 35:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 0.45 | acc: 92%
  Validating... loss: 0.95 | acc: 87%
  âœ“ Model saved! (Val Acc: 87%)

Epoch 50:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 0.25 | acc: 96%
  Validating... loss: 0.88 | acc: 88%
  âœ“ Model saved! (Val Acc: 88%)

Epoch 65:
  Training...   [â”â”â”â”â”â”â”â”â”â”] 100% | loss: 0.18 | acc: 97%
  Validating... loss: 0.92 | acc: 87%
  
Early stopping triggered after 65 epochs

=> Best validation accuracy: 88%
=> Test accuracy: 87.5%
```

---

### **ğŸ¯ Káº¾T LUáº¬N**

**CNN model (`cnn_model.py`) lÃ  lá»±a chá»n tá»‘t nháº¥t khi:**
- âœ… Muá»‘n accuracy cao nháº¥t (85-92%)
- âœ… CÃ³ thá»i gian train (30-60 phÃºt)
- âœ… CÃ³ GPU (khuyáº¿n nghá»‹)
- âœ… CÃ³ Ä‘á»§ data hoáº·c cÃ³ thá»ƒ augment

**Traditional ML (`main.py`) tá»‘t hÆ¡n khi:**
- âœ… Cáº§n train nhanh (2-5 phÃºt)
- âœ… Cáº§n giáº£i thÃ­ch model (feature importance)
- âœ… Ãt data (< 1000 samples)
- âœ… Deploy trÃªn thiáº¿t bá»‹ yáº¿u (embedded)

**Best practice:**
1. Báº¯t Ä‘áº§u vá»›i Traditional ML (`main.py`) â†’ Baseline 76%
2. Náº¿u cáº§n accuracy cao hÆ¡n â†’ CNN (`cnn_model.py`) â†’ 85-92%
3. Ensemble cáº£ 2 â†’ 88-94% ğŸš€

---

## ğŸŒŸ **CÃC MÃ” HÃŒNH DEEP LEARNING KHÃC**

### **ğŸ“‹ Tá»”NG QUAN**

NgoÃ i **CNN 2D** Ä‘Ã£ implement trong `cnn_model.py`, cÃ²n cÃ³ nhiá»u kiáº¿n trÃºc Deep Learning khÃ¡c cho Audio Classification:

---

### **1ï¸âƒ£ RNN/LSTM (Recurrent Neural Networks)**

**NguyÃªn lÃ½:**
```
Audio â†’ MFCC features (40, time_steps)
â†’ LSTM layer xá»­ lÃ½ tuáº§n tá»± tá»«ng time step
â†’ Capture temporal dependencies
â†’ Dense(50) classes
```

**Architecture:**
```python
Input: (batch, time_steps, 40)  # 40 MFCC coefficients
  â†“
LSTM(128, return_sequences=True)
  â†“
LSTM(128)
  â†“
Dense(64, activation='relu')
  â†“
Dropout(0.5)
  â†“
Dense(50, activation='softmax')
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Capture temporal patterns tá»‘t
- âœ… PhÃ¹ há»£p vá»›i sequential data
- âœ… Nhá»› Ä‘Æ°á»£c long-term dependencies

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Training cháº­m (sequential processing)
- âŒ Vanishing gradient problem
- âŒ Accuracy tháº¥p hÆ¡n CNN (75-82%)

**Khi nÃ o dÃ¹ng:**
- Audio cÃ³ rhythm rÃµ rÃ ng (nháº¡c, speech)
- Cáº§n model nháº¹ (~500K params)

**Accuracy: 75-82%**

---

### **2ï¸âƒ£ GRU (Gated Recurrent Unit)**

**NguyÃªn lÃ½:**
```
Simplified LSTM vá»›i Ã­t gates hÆ¡n
â†’ Train nhanh hÆ¡n LSTM
â†’ Performance tÆ°Æ¡ng Ä‘Æ°Æ¡ng
```

**Architecture:**
```python
Input: (batch, time_steps, features)
  â†“
GRU(256, return_sequences=True)
  â†“
GRU(128)
  â†“
Dense(50)
```

**So sÃ¡nh vá»›i LSTM:**
| Aspect | LSTM | GRU |
|--------|------|-----|
| Gates | 3 (input, forget, output) | 2 (reset, update) |
| Parameters | Nhiá»u hÆ¡n | Ãt hÆ¡n ~25% |
| Training Speed | Cháº­m | Nhanh hÆ¡n ~30% |
| Accuracy | TÆ°Æ¡ng Ä‘Æ°Æ¡ng | TÆ°Æ¡ng Ä‘Æ°Æ¡ng |

**Accuracy: 75-80%**

---

### **3ï¸âƒ£ CNN-LSTM Hybrid**

**NguyÃªn lÃ½:**
```
CNN extract spatial features tá»« spectrogram
â†’ LSTM xá»­ lÃ½ temporal sequence
â†’ Best of both worlds
```

**Architecture:**
```python
Input: Spectrogram (128, 128, 1)
  â†“
Conv2D(32) â†’ MaxPool â†’ BatchNorm
  â†“
Conv2D(64) â†’ MaxPool â†’ BatchNorm
  â†“
Conv2D(128) â†’ MaxPool
  â†“
Reshape to (time_steps, features)  # (16, 128)
  â†“
LSTM(256, return_sequences=True)
  â†“
LSTM(128)
  â†“
Dense(50)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… CNN extract frequency patterns
- âœ… LSTM capture temporal evolution
- âœ… Accuracy cao hÆ¡n pure CNN hoáº·c pure LSTM
- âœ… Robust vá»›i temporal variations

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Training cháº­m (50-90 phÃºt)
- âŒ Nhiá»u parameters (~1.5M)
- âŒ KhÃ³ tune hyperparameters

**Khi nÃ o dÃ¹ng:**
- Audio cÃ³ structure phá»©c táº¡p (nháº¡c, speech vá»›i context)
- Muá»‘n tÄƒng 2-3% so vá»›i pure CNN

**Accuracy: 85-90%**

---

### **4ï¸âƒ£ Transformer/Attention Models**

**NguyÃªn lÃ½:**
```
Self-attention mechanism
â†’ Attend to important parts cá»§a spectrogram
â†’ Parallel processing (khÃ´ng sequential)
â†’ SOTA cho nhiá»u tasks
```

**Architecture: AST (Audio Spectrogram Transformer)**
```python
Input: Spectrogram (128, 128)
  â†“
Patch Embedding (16Ã—16 patches)  # Giá»‘ng ViT
  â†“
Positional Encoding
  â†“
Transformer Encoder (12 layers)
  â”œâ”€ Multi-Head Self-Attention
  â”œâ”€ Layer Normalization
  â””â”€ Feed-Forward Network
  â†“
Classification Head
  â†“
Dense(50)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… SOTA accuracy (90-95%)
- âœ… Parallel processing â†’ Fast inference
- âœ… Attention maps â†’ Interpretable
- âœ… Transfer learning tá»« vision models

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cáº§n NHIá»€U data (10,000+ samples)
- âŒ Training ráº¥t cháº­m (2-4 giá»)
- âŒ Nhiá»u parameters (~10M)
- âŒ Cáº§n GPU máº¡nh

**Khi nÃ o dÃ¹ng:**
- CÃ³ dataset lá»›n (10K+ samples)
- CÃ³ GPU tá»‘t (RTX 3080+)
- Muá»‘n accuracy cao nháº¥t

**Accuracy: 90-95%**

---

### **5ï¸âƒ£ ResNet (Residual Network)**

**NguyÃªn lÃ½:**
```
Very deep CNN (50-152 layers)
â†’ Skip connections giáº£i quyáº¿t vanishing gradient
â†’ Pretrained trÃªn ImageNet â†’ Transfer learning
```

**Architecture: ResNet50**
```python
Input: Spectrogram (128, 128, 3)  # Convert to RGB
  â†“
ResNet50 (pretrained on ImageNet)
  â”œâ”€ Conv1: 7Ã—7, 64
  â”œâ”€ Block 1: [1Ã—1,64 | 3Ã—3,64 | 1Ã—1,256] Ã— 3
  â”œâ”€ Block 2: [1Ã—1,128 | 3Ã—3,128 | 1Ã—1,512] Ã— 4
  â”œâ”€ Block 3: [1Ã—1,256 | 3Ã—3,256 | 1Ã—1,1024] Ã— 6
  â””â”€ Block 4: [1Ã—1,512 | 3Ã—3,512 | 1Ã—1,2048] Ã— 3
  â†“
Global Average Pooling
  â†“
Dense(512) â†’ Dropout(0.5) â†’ Dense(50)
```

**Skip Connections:**
```
x â†’ Conv â†’ BatchNorm â†’ ReLU â†’ Conv â†’ BatchNorm
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ +
                                                  â†“
                                               ReLU â†’ Output
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Very deep (50+ layers) khÃ´ng bá»‹ vanishing gradient
- âœ… Pretrained weights â†’ Fast convergence
- âœ… Proven architecture
- âœ… Accuracy cao (88-93%)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Nhiá»u parameters (~25M)
- âŒ Slow training (1-2 giá»)
- âŒ Cáº§n nhiá»u RAM/GPU memory

**Accuracy: 88-93%**

---

### **6ï¸âƒ£ VGG16/VGG19**

**NguyÃªn lÃ½:**
```
Simple but deep CNN
â†’ Only 3Ã—3 convolutions
â†’ Stacking many layers
â†’ Pretrained on ImageNet
```

**Architecture: VGG16**
```python
Input: (128, 128, 3)
  â†“
Conv3-64 â†’ Conv3-64 â†’ MaxPool
  â†“
Conv3-128 â†’ Conv3-128 â†’ MaxPool
  â†“
Conv3-256 â†’ Conv3-256 â†’ Conv3-256 â†’ MaxPool
  â†“
Conv3-512 â†’ Conv3-512 â†’ Conv3-512 â†’ MaxPool
  â†“
Conv3-512 â†’ Conv3-512 â†’ Conv3-512 â†’ MaxPool
  â†“
Flatten â†’ Dense(4096) â†’ Dense(4096) â†’ Dense(50)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Simple architecture
- âœ… Pretrained weights available
- âœ… Good baseline

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Ráº¤T NHIá»€U parameters (~138M)
- âŒ Slow training/inference
- âŒ Outdated (2014)

**Accuracy: 83-88%**

---

### **7ï¸âƒ£ EfficientNet**

**NguyÃªn lÃ½:**
```
Compound scaling: width, depth, resolution
â†’ Scale Ä‘á»u cáº£ 3 dimensions
â†’ Better accuracy/efficiency tradeoff
```

**Architecture: EfficientNet-B0**
```python
Input: (224, 224, 3)
  â†“
MBConv blocks vá»›i varying expansion ratios
  â”œâ”€ MBConv1 (k3Ã—3, 16 filters)
  â”œâ”€ MBConv6 (k3Ã—3, 24 filters) Ã— 2
  â”œâ”€ MBConv6 (k5Ã—5, 40 filters) Ã— 2
  â”œâ”€ MBConv6 (k3Ã—3, 80 filters) Ã— 3
  â”œâ”€ MBConv6 (k5Ã—5, 112 filters) Ã— 3
  â”œâ”€ MBConv6 (k5Ã—5, 192 filters) Ã— 4
  â””â”€ MBConv6 (k3Ã—3, 320 filters)
  â†“
Global Average Pooling
  â†“
Dense(50)
```

**Compound Scaling:**
```
B0: baseline (224Ã—224, 5.3M params)
B1: Ã—1.1 width, Ã—1.1 depth, Ã—1.15 resolution
B2: Ã—1.2 width, Ã—1.3 depth, Ã—1.3 resolution
...
B7: Ã—2.0 width, Ã—3.1 depth, Ã—2.4 resolution (66M params)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Best accuracy/efficiency
- âœ… Nháº¹ hÆ¡n ResNet nhiá»u
- âœ… Pretrained weights
- âœ… State-of-the-art (2019)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Phá»©c táº¡p hÆ¡n simple CNN
- âŒ Cáº§n resize input lá»›n (224Ã—224)

**Accuracy: 88-92%**

---

### **8ï¸âƒ£ 1D CNN**

**NguyÃªn lÃ½:**
```
CNN trá»±c tiáº¿p trÃªn raw waveform (1D signal)
â†’ KhÃ´ng cáº§n convert sang spectrogram
â†’ End-to-end learning
```

**Architecture:**
```python
Input: Raw audio (1, 110250)  # 5s @ 22050 Hz
  â†“
Conv1D(64, kernel=80, stride=4)  # Down to 27562
  â†“
MaxPool1D(4)  # Down to 6890
  â†“
Conv1D(128, kernel=3)
  â†“
MaxPool1D(4)  # Down to 1722
  â†“
Conv1D(256, kernel=3)
  â†“
MaxPool1D(4)  # Down to 430
  â†“
Conv1D(512, kernel=3)
  â†“
Global Average Pooling
  â†“
Dense(256) â†’ Dense(50)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… KhÃ´ng cáº§n preprocessing (STFT, Mel...)
- âœ… End-to-end learning
- âœ… Fast inference
- âœ… Ãt parameters (~300K)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Accuracy tháº¥p hÆ¡n 2D CNN (78-85%)
- âŒ KhÃ³ há»c Ä‘Æ°á»£c frequency patterns
- âŒ Cáº§n nhiá»u data

**Accuracy: 78-85%**

---

### **9ï¸âƒ£ WaveNet**

**NguyÃªn lÃ½:**
```
Dilated causal convolutions
â†’ Exponentially growing receptive field
â†’ Capture long-term dependencies
```

**Architecture:**
```python
Input: Raw waveform
  â†“
Dilated Conv (dilation=1)
  â†“
Dilated Conv (dilation=2)
  â†“
Dilated Conv (dilation=4)
  â†“
Dilated Conv (dilation=8)
  â†“
...
Dilated Conv (dilation=512)
  â†“
1Ã—1 Conv â†’ ReLU â†’ 1Ã—1 Conv
  â†“
Global Pool â†’ Dense(50)
```

**Dilated Convolution:**
```
dilation=1: [x x x]
dilation=2: [x . x . x]
dilation=4: [x . . . x . . . x]

Receptive field grows exponentially!
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Very large receptive field
- âœ… Capture long dependencies
- âœ… High quality

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Ráº¤T CHáº¬M training
- âŒ Designed cho generation, khÃ´ng pháº£i classification
- âŒ Overkill cho ESC-50

**Accuracy: 82-88%**

---

### **ğŸ”Ÿ CRNN (CNN + RNN)**

**Architecture:**
```python
Input: Log-Mel Spectrogram (128, 1000)
  â†“
# CNN feature extraction
Conv2D(64, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
Conv2D(128, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
Conv2D(256, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
  â†“
# Reshape: (batch, freq, time, channels) â†’ (batch, time, features)
Reshape to (batch, 125, 256*16)
  â†“
# RNN temporal modeling
BiLSTM(256) return_sequences=True
BiLSTM(128)
  â†“
# Classification
Dense(256) â†’ Dropout(0.5) â†’ Dense(50)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… CNN learns frequency patterns
- âœ… RNN captures temporal evolution
- âœ… Bidirectional LSTM sees future & past
- âœ… Good for variable-length audio

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Complex architecture
- âŒ Slow training
- âŒ Many hyperparameters to tune

**Accuracy: 85-91%**

---

## ğŸ“Š **Báº¢NG SO SÃNH Tá»”NG Há»¢P**

| Model | Accuracy | Training Time | Parameters | GPU Memory | Khi nÃ o dÃ¹ng |
|-------|----------|---------------|------------|------------|--------------|
| **CNN 2D** âœ… | **85-92%** | 30-60 phÃºt | ~1M | 2-4GB | **Best balance** cho ESC-50 |
| LSTM | 75-82% | 40-80 phÃºt | ~500K | 1-2GB | Sequential patterns, Ã­t data |
| GRU | 75-80% | 30-60 phÃºt | ~400K | 1-2GB | Faster LSTM alternative |
| CNN-LSTM | 85-90% | 50-90 phÃºt | ~1.5M | 3-5GB | Temporal + spatial features |
| Transformer | 90-95% | 2-4 giá» | ~10M | 8-16GB | **Nhiá»u data (10K+), SOTA** |
| ResNet50 | 88-93% | 1-2 giá» | ~25M | 6-10GB | Transfer learning, proven |
| EfficientNet-B0 | 88-92% | 1-1.5 giá» | ~5M | 4-6GB | Best efficiency |
| VGG16 | 83-88% | 1.5-2.5 giá» | ~138M | 10-16GB | Legacy, not recommended |
| 1D CNN | 78-85% | 20-40 phÃºt | ~300K | 1-2GB | Fast, raw waveform |
| WaveNet | 82-88% | 3-6 giá» | ~2M | 4-8GB | High quality, slow |
| CRNN | 85-91% | 1-1.5 giá» | ~1.5M | 3-5GB | Variable-length audio |

---

## âœ… **KHUYáº¾N NGHá»Š THEO USE CASE**

### **ESC-50 (2000 samples) - Hiá»‡n táº¡i:**
```
1. CNN 2D âœ… (Ä‘Ã£ implement)
   - Accuracy: 85-92%
   - Training: 30-60 phÃºt
   - Best choice!

2. CNN-LSTM (náº¿u muá»‘n thá»­)
   - TÄƒng thÃªm 2-3%
   - Cháº­m hÆ¡n 1.5x

3. EfficientNet-B0 (transfer learning)
   - Pretrained weights
   - Tá»‘t cho production
```

### **Dataset lá»›n hÆ¡n (10,000+ samples):**
```
1. Transformer (AST) - SOTA
   - Accuracy: 90-95%
   - Cáº§n GPU máº¡nh

2. EfficientNet-B3/B4
   - Balance accuracy/speed
   
3. Ensemble: CNN + Transformer
   - Accuracy: 92-96%
```

### **Embedded/Mobile (thiáº¿t bá»‹ yáº¿u):**
```
1. 1D CNN
   - Nháº¹ nháº¥t (~300K params)
   - Fast inference
   
2. MobileNet
   - Designed cho mobile
   - Depthwise separable convolutions
```

### **Real-time (< 10ms inference):**
```
1. 1D CNN (optimized)
2. Small 2D CNN (32 filters max)
3. Quantized models (INT8)
```

---

## ğŸ¯ **IMPLEMENTATION PRIORITY**

**ÄÃ£ cÃ³:**
- âœ… Traditional ML (`main.py`) - 76.25%
- âœ… CNN 2D (`cnn_model.py`) - 85-92%

**NÃªn implement tiáº¿p theo:**
1. **CNN-LSTM** - TÄƒng 2-3% ná»¯a â†’ 88-92%
2. **EfficientNet** - Transfer learning â†’ 88-92%
3. **Ensemble** (CNN + SVM) â†’ 88-94%

**Náº¿u cÃ³ nhiá»u data:**
4. **Transformer (AST)** â†’ 90-95%

---

**TÃ¡c giáº£:** AI Assistant  
**NgÃ y:** 2025-10-15  
**Version:** 3.0 (RobustScaler + SelectKBest + ADASYN)  
**Phá»¥ lá»¥c:** CNN Deep Learning Model (PyTorch) + Alternative Models

